{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe51ac8-2f0c-47c2-8b0f-6923bc1b4aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG INFO - Variable counts by frequency:\n",
      "  Q variables: 2\n",
      "  M variables: 3\n",
      "  W variables: 3\n",
      "DEBUG INFO - Combined variable lists:\n",
      "  varlist_list[0]: 5 variables\n",
      "    ['m_1' 'm_2' 'm_3' 'q_1' 'q_2']\n",
      "  varlist_list[1]: 8 variables\n",
      "    ['w_1' 'w_2' 'w_3' 'm_1' 'm_2' 'm_3' 'q_1' 'q_2']\n"
     ]
    }
   ],
   "source": [
    "import SBFVAR\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "\n",
    "# Preparations\n",
    "#---------------------\n",
    "\n",
    "io_data = \"/home/u80856195/git/MUFBVAR-master/examples/hist.xlsx\"\n",
    "\n",
    "#Model Specification\n",
    "H = 96          # forecast horizon\n",
    "nsim = 20      # number of draws from Posterior Density\n",
    "nburn = 0.5     # number of draws to discard\n",
    "nlags = 12   # Number of lags\n",
    "thining = 1     # Thining \n",
    "\n",
    "hyp = [0.09, 4.3, 1, 2.7, 4.3] # Hyperparameters see documentation for details\n",
    "\n",
    "frequencies = [\"Q\",\"M\",\"W\"] # Frequencies\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load the data\n",
    "# --------------\n",
    "data = []\n",
    "for freq in range(len(frequencies)):\n",
    "        freq = frequencies[freq]\n",
    "        data_temp = pd.read_excel(io_data, sheet_name = freq, index_col = 0)\n",
    "        data.append(data_temp)\n",
    "\n",
    "#Transformations\n",
    "trans = [np.array((1,1)), np.array((1,1,1)), np.array((1,1,1))]    \n",
    "\n",
    "\n",
    "# Initialize data class            \n",
    "mufbvar_data = SBFVAR.mufbvar_data(data, trans, frequencies)\n",
    "\n",
    "\n",
    "# Fit and Forecast\n",
    "#--------------------\n",
    "\n",
    "# Initialize model class    \n",
    "model =  SBFVAR.multifrequency_var(nsim, nburn, nlags, thining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_of_interest=None\n",
    "temp_agg='mean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'copy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.temp_agg \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msum\u001b[39m\u001b[33m\"\u001b[39m), \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid temp_agg: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.temp_agg\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Choose \u001b[39m\u001b[33m'\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m'\u001b[39m\u001b[33m or \u001b[39m\u001b[33m'\u001b[39m\u001b[33msum\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Data from mufbvar_data\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m YMX_list = \u001b[43mcopy\u001b[49m.deepcopy(mufbvar_data.YMX_list)\n\u001b[32m     13\u001b[39m YM0_list = copy.deepcopy(mufbvar_data.YM0_list)\n\u001b[32m     14\u001b[39m select_m_list = copy.deepcopy(mufbvar_data.select_m_list)\n",
      "\u001b[31mNameError\u001b[39m: name 'copy' is not defined"
     ]
    }
   ],
   "source": [
    "    explosive_counter = 0\n",
    "    valid_draws = []\n",
    "    \n",
    "    self.nex = 1\n",
    "    self.hyp = hyp\n",
    "    self.temp_agg = temp_agg\n",
    "    self.var_of_interest = var_of_interest\n",
    "    \n",
    "    assert self.temp_agg in (\"mean\", \"sum\"), f\"Invalid temp_agg: {self.temp_agg}. Choose 'mean' or 'sum'.\"\n",
    "    \n",
    "    # Data from mufbvar_data\n",
    "    YMX_list = copy.deepcopy(mufbvar_data.YMX_list)\n",
    "    YM0_list = copy.deepcopy(mufbvar_data.YM0_list)\n",
    "    select_m_list = copy.deepcopy(mufbvar_data.select_m_list)\n",
    "    vars_m_list = copy.deepcopy(mufbvar_data.vars_m_list)\n",
    "    YMh_list = copy.deepcopy(mufbvar_data.YMh_list)\n",
    "    index_list = copy.deepcopy(mufbvar_data.index_list)\n",
    "    frequencies = copy.deepcopy(mufbvar_data.frequencies)\n",
    "    self.frequencies = frequencies\n",
    "    YQX_list = copy.deepcopy(mufbvar_data.YQX_list)\n",
    "    YQ0_list = copy.deepcopy(mufbvar_data.YQ0_list)\n",
    "    select_q = copy.deepcopy(mufbvar_data.select_q)\n",
    "    input_data_Q = copy.deepcopy(mufbvar_data.input_data_Q)\n",
    "    self.input_data_Q = input_data_Q\n",
    "    varlist_list = copy.deepcopy(mufbvar_data.varlist_list[-1])\n",
    "    select_list = copy.deepcopy(mufbvar_data.select_list)\n",
    "    select_c_list = copy.deepcopy(mufbvar_data.select_c_list)\n",
    "    Nm_list = copy.deepcopy(mufbvar_data.Nm_list)\n",
    "    nv_list = copy.deepcopy(mufbvar_data.nv_list)\n",
    "    Nq_list = copy.deepcopy(mufbvar_data.Nq_list)\n",
    "    select_list_sep = copy.deepcopy(mufbvar_data.select_list_sep)\n",
    "    freq_ratio_list = copy.deepcopy(mufbvar_data.freq_ratio_list)\n",
    "    YQ_list = copy.deepcopy(mufbvar_data.YQ_list)\n",
    "    Tstar_list = copy.deepcopy(mufbvar_data.Tstar_list)\n",
    "    T_list = copy.deepcopy(mufbvar_data.T_list)\n",
    "    YDATA_list = copy.deepcopy(mufbvar_data.YDATA_list)\n",
    "    YM_list = copy.deepcopy(mufbvar_data.YM_list)\n",
    "    input_data = copy.deepcopy(mufbvar_data.input_data)\n",
    "    self.input_data = input_data\n",
    "\n",
    "    nburn = round((self.nburn_perc)*math.ceil(self.nsim/self.thining))\n",
    "    self.nburn = nburn\n",
    "    \n",
    "    nlags = self.nlags\n",
    "    p = self.nlags  # Number of lags for VAR\n",
    "    \n",
    "    # Validate frequency ratios\n",
    "    rmw = freq_ratio_list[1]  # Monthly to weekly ratio\n",
    "    rqw = freq_ratio_list[0] * rmw  # Quarterly to weekly ratio\n",
    "    assert rmw == 4, \"Monthly aggregation requires exactly 4 weeks/month\"\n",
    "    assert rqw == 12, \"Quarterly aggregation requires exactly 12 weeks/quarter\"\n",
    "    \n",
    "    # Extract variable counts\n",
    "    Nq = Nq_list[0]  # Quarterly variables\n",
    "    Nm = Nm_list[0]  # Monthly variables\n",
    "    Nw = Nm_list[1]  # Weekly variables\n",
    "    Ntotal = Nq + Nm + Nw  # Total number of variables across all frequencies\n",
    "    \n",
    "    # Extract data for each frequency\n",
    "    YQ = copy.deepcopy(YQ_list[0])  # Quarterly data\n",
    "    YM = copy.deepcopy(YM_list[0])  # Monthly data\n",
    "    YW = copy.deepcopy(YM_list[1])  # Weekly data (second entry in YM_list)\n",
    "    \n",
    "    # Get observation counts\n",
    "    Tw = YW.shape[0]  # Total weekly observations\n",
    "    Tm = YM.shape[0]  # Monthly observations\n",
    "    Tq = YQ.shape[0]  # Quarterly observations\n",
    "    \n",
    "    # Print data dimensions for verification\n",
    "    print(f\"Data dimensions - Weekly: {YW.shape}, Monthly: {YM.shape}, Quarterly: {YQ.shape}\")\n",
    "    \n",
    "    # Number of observations after burn-in (T0 = initial lag period)\n",
    "    T0 = int(nlags)  # Initial observations used for lags\n",
    "    nobs = Tw - T0  \n",
    "    \n",
    "    # STATE SPACE self STRUCTURE\n",
    "    # ---------------------------\n",
    "    \n",
    "    # State vector structure includes all variables in VAR\n",
    "    var_block = Ntotal * p  # All variables with lags for VAR\n",
    "    monthly_latent_block = Nm * rmw  # Month of weekly latent states for monthly vars\n",
    "    quarterly_latent_block = Nq * rqw  # Quarter of weekly latent states for quarterly vars\n",
    "    \n",
    "    # Define indices within state vector\n",
    "    monthly_start = var_block\n",
    "    quarterly_start = monthly_start + monthly_latent_block\n",
    "    \n",
    "    # Total state vector size\n",
    "    nstate = var_block + monthly_latent_block + quarterly_latent_block\n",
    "    \n",
    "    # Print state vector structure details\n",
    "    print(f\"State vector structure:\")\n",
    "    print(f\"  Variables block (with lags): {var_block} states\")\n",
    "    print(f\"  Monthly latent states block: {monthly_latent_block} states (starting at index {monthly_start})\")\n",
    "    print(f\"  Quarterly latent states block: {quarterly_latent_block} states (starting at index {quarterly_start})\")\n",
    "    print(f\"  Total state vector size: {nstate} states\")\n",
    "    \n",
    "    # Initialize matrices for MCMC sampling\n",
    "    Sigmap = np.zeros((math.ceil((self.nsim)/self.thining), Ntotal, Ntotal))\n",
    "    Phip = np.zeros((math.ceil((self.nsim)/self.thining), Ntotal*p+1, Ntotal))  # All variables\n",
    "    Cons = np.zeros((math.ceil((self.nsim)/self.thining), Ntotal))  # Constants for all variables\n",
    "    \n",
    "    # Initialize transition matrix F\n",
    "    F = np.zeros((nstate, nstate))\n",
    "    \n",
    "    # Initialize VAR coefficients for all variables\n",
    "    Phi = np.vstack((0.95 * np.eye(Ntotal), np.zeros((Ntotal*(p-1), Ntotal)), np.zeros((1, Ntotal))))  # Last row for constant\n",
    "    \n",
    "    # Set VAR dynamics in transition matrix\n",
    "    F[:Ntotal, :Ntotal*p] = Phi[:-1, :].T  # VAR coefficients (excluding constant)\n",
    "    \n",
    "    # Lag-shifting section for all variables\n",
    "    for i in range(p-1):\n",
    "        F[Ntotal*(i+1):Ntotal*(i+2), Ntotal*i:Ntotal*(i+1)] = np.eye(Ntotal)\n",
    "    \n",
    "    # Monthly latent states: shifting blocks with weekly influence\n",
    "    # Week 1 is influenced by weekly variables (10%)\n",
    "    F[monthly_start:monthly_start+Nm, :Nw] = 0.1 * np.eye(Nm, Nw)\n",
    "    \n",
    "    # Shift weeks within each month, creating a diagonal structure\n",
    "    for i in range(rmw-1):\n",
    "        src_pos = monthly_start + i*Nm\n",
    "        dest_pos = monthly_start + (i+1)*Nm\n",
    "        F[dest_pos:dest_pos+Nm, src_pos:src_pos+Nm] = np.eye(Nm)\n",
    "    \n",
    "    # Quarterly latent states: shifting blocks with weekly influence\n",
    "    # Week 1 is influenced by weekly variables (5%)\n",
    "    F[quarterly_start:quarterly_start+Nq, :Nw] = 0.05 * np.eye(Nq, Nw)\n",
    "    \n",
    "    # Shift weeks within each quarter\n",
    "    for i in range(rqw-1):\n",
    "        src_pos = quarterly_start + i*Nq\n",
    "        dest_pos = quarterly_start + (i+1)*Nq\n",
    "        F[dest_pos:dest_pos+Nq, src_pos:src_pos+Nq] = np.eye(Nq)\n",
    "    \n",
    "    # Constant term vector\n",
    "    c = np.zeros((nstate, 1))\n",
    "    c[:Ntotal] = np.atleast_2d(Phi[-1, :]).T  # Constants for all variables\n",
    "    \n",
    "    # MEASUREMENT EQUATIONS WITH ENHANCED CONSTRAINTS\n",
    "    # ---------------------------------------------\n",
    "    \n",
    "    # Weekly measurement (always available)\n",
    "    H_w = np.zeros((Nw, nstate))\n",
    "    H_w[:, :Nw] = np.eye(Nw)  # Directly observe first Nw state elements\n",
    "    \n",
    "    # Monthly measurement (available at month-end)\n",
    "    H_m = np.zeros((Nm, nstate))\n",
    "    # For monthly variables, aggregate all weekly latent states\n",
    "    for m in range(Nm):\n",
    "        for w in range(rmw):\n",
    "            state_idx = monthly_start + w*Nm + m\n",
    "            if self.temp_agg == 'mean':\n",
    "                H_m[m, state_idx] = 1.0/rmw  # Average of weeks in month\n",
    "            else:  # 'sum'\n",
    "                H_m[m, state_idx] = 1.0  # Sum of weeks in month\n",
    "    \n",
    "    # Quarterly measurement (available at quarter-end)\n",
    "    H_q = np.zeros((Nq, nstate))\n",
    "    # For quarterly variables, aggregate all weekly latent states\n",
    "    for q in range(Nq):\n",
    "        for w in range(rqw):\n",
    "            state_idx = quarterly_start + w*Nq + q\n",
    "            if self.temp_agg == 'mean':\n",
    "                H_q[q, state_idx] = 1.0/rqw  # Average of weeks in quarter\n",
    "            else:  # 'sum'\n",
    "                H_q[q, state_idx] = 1.0  # Sum of weeks in quarter\n",
    "    \n",
    "    # Add direct constraints to also enforce VAR block alignment\n",
    "    # This creates a stronger link between VAR variables and latent states\n",
    "    H_m_constraint = np.zeros((Nm, nstate))\n",
    "    H_q_constraint = np.zeros((Nq, nstate))\n",
    "    \n",
    "    # Link monthly variables in VAR block with first week of latent states\n",
    "    for m in range(Nm):\n",
    "        # VAR block for monthly variable\n",
    "        H_m_constraint[m, Nw+m] = 1.0\n",
    "        # First week latent state\n",
    "        H_m_constraint[m, monthly_start+m] = -1.0\n",
    "    \n",
    "    # Link quarterly variables in VAR block with first week of latent states\n",
    "    for q in range(Nq):\n",
    "        # VAR block for quarterly variable\n",
    "        H_q_constraint[q, Nw+Nm+q] = 1.0\n",
    "        # First week latent state\n",
    "        H_q_constraint[q, quarterly_start+q] = -1.0\n",
    "    \n",
    "    # Print measurement matrix details for verification\n",
    "    print(\"\\nMeasurement equations:\")\n",
    "    print(f\"Weekly measurement: Using {Nw} direct weekly observations\")\n",
    "    for m in range(min(2, Nm)):\n",
    "        active_indices = np.where(H_m[m] != 0)[0]\n",
    "        print(f\"Monthly var {m+1}: Aggregating {len(active_indices)} weekly latent states with weights {H_m[m, active_indices[0]]:.6f}\")\n",
    "        \n",
    "    for q in range(min(2, Nq)):\n",
    "        active_indices = np.where(H_q[q] != 0)[0]\n",
    "        print(f\"Quarterly var {q+1}: Aggregating {len(active_indices)} weekly latent states with weights {H_q[q, active_indices[0]]:.6f}\")\n",
    "    \n",
    "    print(\"Added VAR-to-latent state alignment constraints\")\n",
    "    \n",
    "    # SYSTEM NOISE AND INITIALIZATION\n",
    "    # ------------------------------\n",
    "    \n",
    "    # System noise affects VAR variables differently than latent states\n",
    "    Q = np.zeros((nstate, nstate))\n",
    "    \n",
    "    # VAR block: moderate process noise\n",
    "    Q[:Ntotal, :Ntotal] = 1e-4 * np.eye(Ntotal)\n",
    "    \n",
    "    # Monthly latent states: significantly lower process noise\n",
    "    for m in range(Nm):\n",
    "        for w in range(rmw):\n",
    "            idx = monthly_start + w*Nm + m\n",
    "            Q[idx, idx] = 1e-6  # Reduced process noise for smoother weekly patterns\n",
    "    \n",
    "    # Quarterly latent states: lowest process noise\n",
    "    for q in range(Nq):\n",
    "        for w in range(rqw):\n",
    "            idx = quarterly_start + w*Nq + q\n",
    "            Q[idx, idx] = 1e-7  # Even lower process noise for quarterly patterns\n",
    "    \n",
    "    # Initialize state vector\n",
    "    a_t = np.zeros(nstate)\n",
    "    P_t = np.eye(nstate) * 1e-3  # Initialize P_t here first\n",
    "\n",
    "    # Higher uncertainty for VAR block\n",
    "    P_t[:Ntotal, :Ntotal] = np.eye(Ntotal) * 1e-2\n",
    "    # Initialize weekly variables with available data\n",
    "    if YW.shape[0] > 0:\n",
    "        a_t[:Nw] = YW[0, :Nw]\n",
    "        print(f\"Weekly vars initialized with first observation\")\n",
    "    \n",
    "    # Initialize monthly variables in VAR block\n",
    "    if YM.shape[0] > 0:\n",
    "        a_t[Nw:Nw+Nm] = YM[0, :]\n",
    "    \n",
    "    # Initialize quarterly variables in VAR block\n",
    "    if YQ.shape[0] > 0:\n",
    "        a_t[Nw+Nm:Ntotal] = YQ[0, :]\n",
    "    \n",
    "    # IMPROVED INITIALIZATION FOR LATENT STATES\n",
    "    # Initialize monthly latent states with reasonable patterns\n",
    "    if YM.shape[0] > 0:\n",
    "        for m in range(Nm):\n",
    "            m_value = YM[0, m]\n",
    "            # Create a realistic weekly pattern around the observed value\n",
    "            for w in range(rmw):\n",
    "                # Small variations (±5%)\n",
    "                a_t[monthly_start + w*Nm + m] = m_value * (0.95 + 0.1 * (w / (rmw-1)))\n",
    "                # Lower initial uncertainty\n",
    "                P_t[monthly_start + w*Nm + m, monthly_start + w*Nm + m] = 0.01\n",
    "            print(f\"Monthly var {m+1} initialized with more stable weekly pattern\")\n",
    "    \n",
    "    # Initialize quarterly latent states with reasonable patterns\n",
    "    if YQ.shape[0] > 0:\n",
    "        for q in range(Nq):\n",
    "            q_value = YQ[0, q]\n",
    "            # Create a realistic weekly pattern for quarterly data\n",
    "            for w in range(rqw):\n",
    "                # Gentle seasonal pattern\n",
    "                a_t[quarterly_start + w*Nq + q] = q_value * (0.9 + 0.2 * np.sin(np.pi * w / rqw))\n",
    "                # Lower initial uncertainty\n",
    "                P_t[quarterly_start + w*Nq + q, quarterly_start + w*Nq + q] = 0.01\n",
    "            print(f\"Quarterly var {q+1} initialized with more stable weekly pattern\")\n",
    "    \n",
    "    # PREPARE KALMAN FILTER DATA\n",
    "    # -------------------------\n",
    "    \n",
    "    # Prepare observed data vectors with clear frequency markers\n",
    "    q_obs_periods = np.zeros(Tw, dtype=bool)  # Quarters observed\n",
    "    m_obs_periods = np.zeros(Tw, dtype=bool)  # Months observed\n",
    "    \n",
    "    # Mark which weekly periods have quarterly/monthly observations\n",
    "    # Quarterly data is available at the end of each quarter\n",
    "    for t in range(rqw-1, Tw, rqw):\n",
    "        q_idx = t // rqw\n",
    "        if q_idx < Tq:\n",
    "            q_obs_periods[t] = True\n",
    "    \n",
    "    # Monthly data is available at the end of each month\n",
    "    for t in range(rmw-1, Tw, rmw):\n",
    "        m_idx = t // rmw\n",
    "        if m_idx < Tm:\n",
    "            m_obs_periods[t] = True\n",
    "    \n",
    "    # Storage for filtered and smoothed states\n",
    "    a_filtered = np.zeros((nobs, nstate))\n",
    "    P_filtered = np.zeros((nobs, nstate, nstate))\n",
    "    a_draws = np.zeros((self.nsim, nobs, nstate))\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import deque\n",
    "from scipy.linalg import companion\n",
    "from scipy.stats import invwishart\n",
    "import pandas as pd\n",
    "from scipy.stats import multivariate_normal\n",
    "from datetime import datetime\n",
    "from pandas.tseries.offsets import Week, MonthBegin, QuarterBegin, Day\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "import matplotlib.backends.backend_pdf\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "import pickle\n",
    "import copy\n",
    "from SBFVAR.cholcov.cholcov_module import cholcovOrEigendecomp\n",
    "from SBFVAR.inverse.matrix_inversion import invert_matrix\n",
    "from SBFVAR.mfbvar_funcs import calc_yyact, is_explosive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dimensions - Weekly: (947, 3), Monthly: (236, 3), Quarterly: (234, 2)\n",
      "State vector structure:\n",
      "  Variables block (with lags): 96 states\n",
      "  Monthly latent states block: 12 states (starting at index 96)\n",
      "  Quarterly latent states block: 24 states (starting at index 108)\n",
      "  Total state vector size: 132 states\n",
      "\n",
      "Measurement equations:\n",
      "Weekly measurement: Using 3 direct weekly observations\n",
      "Monthly var 1: Aggregating 4 weekly latent states with weights 0.250000\n",
      "Monthly var 2: Aggregating 4 weekly latent states with weights 0.250000\n",
      "Quarterly var 1: Aggregating 12 weekly latent states with weights 0.083333\n",
      "Quarterly var 2: Aggregating 12 weekly latent states with weights 0.083333\n",
      "Added VAR-to-latent state alignment constraints\n",
      "Weekly vars initialized with first observation\n",
      "Monthly var 1 initialized with more stable weekly pattern\n",
      "Monthly var 2 initialized with more stable weekly pattern\n",
      "Monthly var 3 initialized with more stable weekly pattern\n",
      "Quarterly var 1 initialized with more stable weekly pattern\n",
      "Quarterly var 2 initialized with more stable weekly pattern\n"
     ]
    }
   ],
   "source": [
    "    explosive_counter = 0\n",
    "    valid_draws = []\n",
    "    \n",
    "    self.nex = 1\n",
    "    self.hyp = hyp\n",
    "    self.temp_agg = temp_agg\n",
    "    self.var_of_interest = var_of_interest\n",
    "    \n",
    "    assert self.temp_agg in (\"mean\", \"sum\"), f\"Invalid temp_agg: {self.temp_agg}. Choose 'mean' or 'sum'.\"\n",
    "    \n",
    "    # Data from mufbvar_data\n",
    "    YMX_list = copy.deepcopy(mufbvar_data.YMX_list)\n",
    "    YM0_list = copy.deepcopy(mufbvar_data.YM0_list)\n",
    "    select_m_list = copy.deepcopy(mufbvar_data.select_m_list)\n",
    "    vars_m_list = copy.deepcopy(mufbvar_data.vars_m_list)\n",
    "    YMh_list = copy.deepcopy(mufbvar_data.YMh_list)\n",
    "    index_list = copy.deepcopy(mufbvar_data.index_list)\n",
    "    frequencies = copy.deepcopy(mufbvar_data.frequencies)\n",
    "    self.frequencies = frequencies\n",
    "    YQX_list = copy.deepcopy(mufbvar_data.YQX_list)\n",
    "    YQ0_list = copy.deepcopy(mufbvar_data.YQ0_list)\n",
    "    select_q = copy.deepcopy(mufbvar_data.select_q)\n",
    "    input_data_Q = copy.deepcopy(mufbvar_data.input_data_Q)\n",
    "    self.input_data_Q = input_data_Q\n",
    "    varlist_list = copy.deepcopy(mufbvar_data.varlist_list[-1])\n",
    "    select_list = copy.deepcopy(mufbvar_data.select_list)\n",
    "    select_c_list = copy.deepcopy(mufbvar_data.select_c_list)\n",
    "    Nm_list = copy.deepcopy(mufbvar_data.Nm_list)\n",
    "    nv_list = copy.deepcopy(mufbvar_data.nv_list)\n",
    "    Nq_list = copy.deepcopy(mufbvar_data.Nq_list)\n",
    "    select_list_sep = copy.deepcopy(mufbvar_data.select_list_sep)\n",
    "    freq_ratio_list = copy.deepcopy(mufbvar_data.freq_ratio_list)\n",
    "    YQ_list = copy.deepcopy(mufbvar_data.YQ_list)\n",
    "    Tstar_list = copy.deepcopy(mufbvar_data.Tstar_list)\n",
    "    T_list = copy.deepcopy(mufbvar_data.T_list)\n",
    "    YDATA_list = copy.deepcopy(mufbvar_data.YDATA_list)\n",
    "    YM_list = copy.deepcopy(mufbvar_data.YM_list)\n",
    "    input_data = copy.deepcopy(mufbvar_data.input_data)\n",
    "    self.input_data = input_data\n",
    "\n",
    "    nburn = round((self.nburn_perc)*math.ceil(self.nsim/self.thining))\n",
    "    self.nburn = nburn\n",
    "    \n",
    "    nlags = self.nlags\n",
    "    p = self.nlags  # Number of lags for VAR\n",
    "    \n",
    "    # Validate frequency ratios\n",
    "    rmw = freq_ratio_list[1]  # Monthly to weekly ratio\n",
    "    rqw = freq_ratio_list[0] * rmw  # Quarterly to weekly ratio\n",
    "    assert rmw == 4, \"Monthly aggregation requires exactly 4 weeks/month\"\n",
    "    assert rqw == 12, \"Quarterly aggregation requires exactly 12 weeks/quarter\"\n",
    "    \n",
    "    # Extract variable counts\n",
    "    Nq = Nq_list[0]  # Quarterly variables\n",
    "    Nm = Nm_list[0]  # Monthly variables\n",
    "    Nw = Nm_list[1]  # Weekly variables\n",
    "    Ntotal = Nq + Nm + Nw  # Total number of variables across all frequencies\n",
    "    \n",
    "    # Extract data for each frequency\n",
    "    YQ = copy.deepcopy(YQ_list[0])  # Quarterly data\n",
    "    YM = copy.deepcopy(YM_list[0])  # Monthly data\n",
    "    YW = copy.deepcopy(YM_list[1])  # Weekly data (second entry in YM_list)\n",
    "    \n",
    "    # Get observation counts\n",
    "    Tw = YW.shape[0]  # Total weekly observations\n",
    "    Tm = YM.shape[0]  # Monthly observations\n",
    "    Tq = YQ.shape[0]  # Quarterly observations\n",
    "    \n",
    "    # Print data dimensions for verification\n",
    "    print(f\"Data dimensions - Weekly: {YW.shape}, Monthly: {YM.shape}, Quarterly: {YQ.shape}\")\n",
    "    \n",
    "    # Number of observations after burn-in (T0 = initial lag period)\n",
    "    T0 = int(nlags)  # Initial observations used for lags\n",
    "    nobs = Tw - T0  \n",
    "    \n",
    "    # STATE SPACE self STRUCTURE\n",
    "    # ---------------------------\n",
    "    \n",
    "    # State vector structure includes all variables in VAR\n",
    "    var_block = Ntotal * p  # All variables with lags for VAR\n",
    "    monthly_latent_block = Nm * rmw  # Month of weekly latent states for monthly vars\n",
    "    quarterly_latent_block = Nq * rqw  # Quarter of weekly latent states for quarterly vars\n",
    "    \n",
    "    # Define indices within state vector\n",
    "    monthly_start = var_block\n",
    "    quarterly_start = monthly_start + monthly_latent_block\n",
    "    \n",
    "    # Total state vector size\n",
    "    nstate = var_block + monthly_latent_block + quarterly_latent_block\n",
    "    \n",
    "    # Print state vector structure details\n",
    "    print(f\"State vector structure:\")\n",
    "    print(f\"  Variables block (with lags): {var_block} states\")\n",
    "    print(f\"  Monthly latent states block: {monthly_latent_block} states (starting at index {monthly_start})\")\n",
    "    print(f\"  Quarterly latent states block: {quarterly_latent_block} states (starting at index {quarterly_start})\")\n",
    "    print(f\"  Total state vector size: {nstate} states\")\n",
    "    \n",
    "    # Initialize matrices for MCMC sampling\n",
    "    Sigmap = np.zeros((math.ceil((self.nsim)/self.thining), Ntotal, Ntotal))\n",
    "    Phip = np.zeros((math.ceil((self.nsim)/self.thining), Ntotal*p+1, Ntotal))  # All variables\n",
    "    Cons = np.zeros((math.ceil((self.nsim)/self.thining), Ntotal))  # Constants for all variables\n",
    "    \n",
    "    # Initialize transition matrix F\n",
    "    F = np.zeros((nstate, nstate))\n",
    "    \n",
    "    # Initialize VAR coefficients for all variables\n",
    "    Phi = np.vstack((0.95 * np.eye(Ntotal), np.zeros((Ntotal*(p-1), Ntotal)), np.zeros((1, Ntotal))))  # Last row for constant\n",
    "    \n",
    "    # Set VAR dynamics in transition matrix\n",
    "    F[:Ntotal, :Ntotal*p] = Phi[:-1, :].T  # VAR coefficients (excluding constant)\n",
    "    \n",
    "    # Lag-shifting section for all variables\n",
    "    for i in range(p-1):\n",
    "        F[Ntotal*(i+1):Ntotal*(i+2), Ntotal*i:Ntotal*(i+1)] = np.eye(Ntotal)\n",
    "    \n",
    "    # Monthly latent states: shifting blocks with weekly influence\n",
    "    # Week 1 is influenced by weekly variables (10%)\n",
    "    F[monthly_start:monthly_start+Nm, :Nw] = 0.1 * np.eye(Nm, Nw)\n",
    "    \n",
    "    # Shift weeks within each month, creating a diagonal structure\n",
    "    for i in range(rmw-1):\n",
    "        src_pos = monthly_start + i*Nm\n",
    "        dest_pos = monthly_start + (i+1)*Nm\n",
    "        F[dest_pos:dest_pos+Nm, src_pos:src_pos+Nm] = np.eye(Nm)\n",
    "    \n",
    "    # Quarterly latent states: shifting blocks with weekly influence\n",
    "    # Week 1 is influenced by weekly variables (5%)\n",
    "    F[quarterly_start:quarterly_start+Nq, :Nw] = 0.05 * np.eye(Nq, Nw)\n",
    "    \n",
    "    # Shift weeks within each quarter\n",
    "    for i in range(rqw-1):\n",
    "        src_pos = quarterly_start + i*Nq\n",
    "        dest_pos = quarterly_start + (i+1)*Nq\n",
    "        F[dest_pos:dest_pos+Nq, src_pos:src_pos+Nq] = np.eye(Nq)\n",
    "    \n",
    "    # Constant term vector\n",
    "    c = np.zeros((nstate, 1))\n",
    "    c[:Ntotal] = np.atleast_2d(Phi[-1, :]).T  # Constants for all variables\n",
    "    \n",
    "    # MEASUREMENT EQUATIONS WITH ENHANCED CONSTRAINTS\n",
    "    # ---------------------------------------------\n",
    "    \n",
    "    # Weekly measurement (always available)\n",
    "    H_w = np.zeros((Nw, nstate))\n",
    "    H_w[:, :Nw] = np.eye(Nw)  # Directly observe first Nw state elements\n",
    "    \n",
    "    # Monthly measurement (available at month-end)\n",
    "    H_m = np.zeros((Nm, nstate))\n",
    "    # For monthly variables, aggregate all weekly latent states\n",
    "    for m in range(Nm):\n",
    "        for w in range(rmw):\n",
    "            state_idx = monthly_start + w*Nm + m\n",
    "            if self.temp_agg == 'mean':\n",
    "                H_m[m, state_idx] = 1.0/rmw  # Average of weeks in month\n",
    "            else:  # 'sum'\n",
    "                H_m[m, state_idx] = 1.0  # Sum of weeks in month\n",
    "    \n",
    "    # Quarterly measurement (available at quarter-end)\n",
    "    H_q = np.zeros((Nq, nstate))\n",
    "    # For quarterly variables, aggregate all weekly latent states\n",
    "    for q in range(Nq):\n",
    "        for w in range(rqw):\n",
    "            state_idx = quarterly_start + w*Nq + q\n",
    "            if self.temp_agg == 'mean':\n",
    "                H_q[q, state_idx] = 1.0/rqw  # Average of weeks in quarter\n",
    "            else:  # 'sum'\n",
    "                H_q[q, state_idx] = 1.0  # Sum of weeks in quarter\n",
    "    \n",
    "    # Add direct constraints to also enforce VAR block alignment\n",
    "    # This creates a stronger link between VAR variables and latent states\n",
    "    H_m_constraint = np.zeros((Nm, nstate))\n",
    "    H_q_constraint = np.zeros((Nq, nstate))\n",
    "    \n",
    "    # Link monthly variables in VAR block with first week of latent states\n",
    "    for m in range(Nm):\n",
    "        # VAR block for monthly variable\n",
    "        H_m_constraint[m, Nw+m] = 1.0\n",
    "        # First week latent state\n",
    "        H_m_constraint[m, monthly_start+m] = -1.0\n",
    "    \n",
    "    # Link quarterly variables in VAR block with first week of latent states\n",
    "    for q in range(Nq):\n",
    "        # VAR block for quarterly variable\n",
    "        H_q_constraint[q, Nw+Nm+q] = 1.0\n",
    "        # First week latent state\n",
    "        H_q_constraint[q, quarterly_start+q] = -1.0\n",
    "    \n",
    "    # Print measurement matrix details for verification\n",
    "    print(\"\\nMeasurement equations:\")\n",
    "    print(f\"Weekly measurement: Using {Nw} direct weekly observations\")\n",
    "    for m in range(min(2, Nm)):\n",
    "        active_indices = np.where(H_m[m] != 0)[0]\n",
    "        print(f\"Monthly var {m+1}: Aggregating {len(active_indices)} weekly latent states with weights {H_m[m, active_indices[0]]:.6f}\")\n",
    "        \n",
    "    for q in range(min(2, Nq)):\n",
    "        active_indices = np.where(H_q[q] != 0)[0]\n",
    "        print(f\"Quarterly var {q+1}: Aggregating {len(active_indices)} weekly latent states with weights {H_q[q, active_indices[0]]:.6f}\")\n",
    "    \n",
    "    print(\"Added VAR-to-latent state alignment constraints\")\n",
    "    \n",
    "    # SYSTEM NOISE AND INITIALIZATION\n",
    "    # ------------------------------\n",
    "    \n",
    "    # System noise affects VAR variables differently than latent states\n",
    "    Q = np.zeros((nstate, nstate))\n",
    "    \n",
    "    # VAR block: moderate process noise\n",
    "    Q[:Ntotal, :Ntotal] = 1e-4 * np.eye(Ntotal)\n",
    "    \n",
    "    # Monthly latent states: significantly lower process noise\n",
    "    for m in range(Nm):\n",
    "        for w in range(rmw):\n",
    "            idx = monthly_start + w*Nm + m\n",
    "            Q[idx, idx] = 1e-6  # Reduced process noise for smoother weekly patterns\n",
    "    \n",
    "    # Quarterly latent states: lowest process noise\n",
    "    for q in range(Nq):\n",
    "        for w in range(rqw):\n",
    "            idx = quarterly_start + w*Nq + q\n",
    "            Q[idx, idx] = 1e-7  # Even lower process noise for quarterly patterns\n",
    "    \n",
    "    # Initialize state vector\n",
    "    a_t = np.zeros(nstate)\n",
    "    P_t = np.eye(nstate) * 1e-3  # Initialize P_t here first\n",
    "\n",
    "    # Higher uncertainty for VAR block\n",
    "    P_t[:Ntotal, :Ntotal] = np.eye(Ntotal) * 1e-2\n",
    "    # Initialize weekly variables with available data\n",
    "    if YW.shape[0] > 0:\n",
    "        a_t[:Nw] = YW[0, :Nw]\n",
    "        print(f\"Weekly vars initialized with first observation\")\n",
    "    \n",
    "    # Initialize monthly variables in VAR block\n",
    "    if YM.shape[0] > 0:\n",
    "        a_t[Nw:Nw+Nm] = YM[0, :]\n",
    "    \n",
    "    # Initialize quarterly variables in VAR block\n",
    "    if YQ.shape[0] > 0:\n",
    "        a_t[Nw+Nm:Ntotal] = YQ[0, :]\n",
    "    \n",
    "    # IMPROVED INITIALIZATION FOR LATENT STATES\n",
    "    # Initialize monthly latent states with reasonable patterns\n",
    "    if YM.shape[0] > 0:\n",
    "        for m in range(Nm):\n",
    "            m_value = YM[0, m]\n",
    "            # Create a realistic weekly pattern around the observed value\n",
    "            for w in range(rmw):\n",
    "                # Small variations (±5%)\n",
    "                a_t[monthly_start + w*Nm + m] = m_value * (0.95 + 0.1 * (w / (rmw-1)))\n",
    "                # Lower initial uncertainty\n",
    "                P_t[monthly_start + w*Nm + m, monthly_start + w*Nm + m] = 0.01\n",
    "            print(f\"Monthly var {m+1} initialized with more stable weekly pattern\")\n",
    "    \n",
    "    # Initialize quarterly latent states with reasonable patterns\n",
    "    if YQ.shape[0] > 0:\n",
    "        for q in range(Nq):\n",
    "            q_value = YQ[0, q]\n",
    "            # Create a realistic weekly pattern for quarterly data\n",
    "            for w in range(rqw):\n",
    "                # Gentle seasonal pattern\n",
    "                a_t[quarterly_start + w*Nq + q] = q_value * (0.9 + 0.2 * np.sin(np.pi * w / rqw))\n",
    "                # Lower initial uncertainty\n",
    "                P_t[quarterly_start + w*Nq + q, quarterly_start + w*Nq + q] = 0.01\n",
    "            print(f\"Quarterly var {q+1} initialized with more stable weekly pattern\")\n",
    "    \n",
    "    # PREPARE KALMAN FILTER DATA\n",
    "    # -------------------------\n",
    "    \n",
    "    # Prepare observed data vectors with clear frequency markers\n",
    "    q_obs_periods = np.zeros(Tw, dtype=bool)  # Quarters observed\n",
    "    m_obs_periods = np.zeros(Tw, dtype=bool)  # Months observed\n",
    "    \n",
    "    # Mark which weekly periods have quarterly/monthly observations\n",
    "    # Quarterly data is available at the end of each quarter\n",
    "    for t in range(rqw-1, Tw, rqw):\n",
    "        q_idx = t // rqw\n",
    "        if q_idx < Tq:\n",
    "            q_obs_periods[t] = True\n",
    "    \n",
    "    # Monthly data is available at the end of each month\n",
    "    for t in range(rmw-1, Tw, rmw):\n",
    "        m_idx = t // rmw\n",
    "        if m_idx < Tm:\n",
    "            m_obs_periods[t] = True\n",
    "    \n",
    "    # Storage for filtered and smoothed states\n",
    "    a_filtered = np.zeros((nobs, nstate))\n",
    "    P_filtered = np.zeros((nobs, nstate, nstate))\n",
    "    a_draws = np.zeros((self.nsim, nobs, nstate))\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (<ipython-input-8-210a0cdbe1db>, line 954)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 954\u001b[39m\n\u001b[31m    \u001b[39m\n    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m incomplete input\n"
     ]
    }
   ],
   "source": [
    "        if j > 0:\n",
    "            a_t = a_draws[j-1, -1]\n",
    "            P_t = P_filtered[-1]\n",
    "        \n",
    "        # Kalman filter loop through all periods\n",
    "        for t in range(nobs):\n",
    "            # Current week index\n",
    "            w_idx = T0 + t\n",
    "            \n",
    "            # PREDICTION STEP\n",
    "            # --------------\n",
    "            a_pred = F @ a_t + c.flatten()\n",
    "            P_pred = F @ P_t @ F.T + Q\n",
    "            P_pred = 0.5 * (P_pred + P_pred.T)  # Ensure perfect symmetry\n",
    "            \n",
    "            # DETERMINE AVAILABLE OBSERVATIONS\n",
    "            # -----------------------------\n",
    "            \n",
    "            # Check which observations are available at this period\n",
    "            is_quarter_end = q_obs_periods[w_idx] if w_idx < len(q_obs_periods) else False\n",
    "            is_month_end = m_obs_periods[w_idx] if w_idx < len(m_obs_periods) else False\n",
    "            \n",
    "            # Get indices for the observation vectors\n",
    "            q_idx = w_idx // rqw if is_quarter_end else -1\n",
    "            m_idx = w_idx // rmw if is_month_end else -1\n",
    "            \n",
    "            # Debug output for first few periods\n",
    "            if j == 0 and t < 5:\n",
    "                print(f\"Period {t+1}: week_idx={w_idx}, quarter_end={is_quarter_end}, month_end={is_month_end}\")\n",
    "                if is_quarter_end:\n",
    "                    print(f\"  Quarterly observation: {YQ[q_idx]}\")\n",
    "                if is_month_end:\n",
    "                    print(f\"  Monthly observation: {YM[m_idx]}\")\n",
    "            \n",
    "            # BUILD ENHANCED MEASUREMENT MATRICES AND OBSERVATION VECTOR\n",
    "            # -----------------------------------------------------\n",
    "            \n",
    "            # Start with weekly observations (always available)\n",
    "            H_matrices = [H_w]\n",
    "            y_obs = [YW[w_idx]]\n",
    "            \n",
    "            # Add monthly observations if available\n",
    "            monthly_constraints_added = False\n",
    "            if is_month_end and m_idx >= 0 and m_idx < YM.shape[0]:\n",
    "                H_matrices.append(H_m)\n",
    "                y_obs.append(YM[m_idx])\n",
    "                \n",
    "                # Always add the constraint that links VAR block to latent states\n",
    "                H_matrices.append(H_m_constraint)\n",
    "                y_obs.append(np.zeros(Nm))  # Zero difference means equality constraint\n",
    "                monthly_constraints_added = True\n",
    "            \n",
    "            # Add quarterly observations if available\n",
    "            quarterly_constraints_added = False\n",
    "            if is_quarter_end and q_idx >= 0 and q_idx < YQ.shape[0]:\n",
    "                H_matrices.append(H_q)\n",
    "                y_obs.append(YQ[q_idx])\n",
    "                \n",
    "                # Always add the constraint that links VAR block to latent states\n",
    "                H_matrices.append(H_q_constraint)\n",
    "                y_obs.append(np.zeros(Nq))  # Zero difference means equality constraint\n",
    "                quarterly_constraints_added = True\n",
    "            \n",
    "            # Also enforce VAR-latent alignment constraints at every period\n",
    "            # (not just at month/quarter end)\n",
    "            if not monthly_constraints_added and t % 5 == 0:  # Every 5 periods to avoid too much constraint\n",
    "                H_matrices.append(H_m_constraint)\n",
    "                y_obs.append(np.zeros(Nm))\n",
    "            \n",
    "            if not quarterly_constraints_added and t % 10 == 0:  # Less frequent for quarterly\n",
    "                H_matrices.append(H_q_constraint)\n",
    "                y_obs.append(np.zeros(Nq))\n",
    "            \n",
    "            # Combined measurement matrix and observation vector\n",
    "            H = np.vstack(H_matrices)\n",
    "            y = np.concatenate(y_obs)\n",
    "            \n",
    "            # DIFFERENT MEASUREMENT NOISE BY FREQUENCY - EXTREMELY PRECISE FOR CONSTRAINTS\n",
    "            # ---------------------------------------------------------------------\n",
    "            \n",
    "            # Create measurement noise matrix with precision scaled by frequency\n",
    "            R = np.zeros((len(y), len(y)))\n",
    "            \n",
    "            # Current position in the observation vector\n",
    "            obs_pos = 0\n",
    "            \n",
    "            # Weekly measurement noise (standard precision)\n",
    "            R[obs_pos:obs_pos+Nw, obs_pos:obs_pos+Nw] = np.eye(Nw) * 1e-3\n",
    "            obs_pos += Nw\n",
    "            \n",
    "            # Monthly measurement noise (extreme precision to enforce constraint)\n",
    "            if is_month_end and m_idx >= 0 and m_idx < YM.shape[0]:\n",
    "                R[obs_pos:obs_pos+Nm, obs_pos:obs_pos+Nm] = np.eye(Nm) * 1e-12\n",
    "                obs_pos += Nm\n",
    "                \n",
    "                # VAR-to-latent constraint noise (extremely low)\n",
    "                R[obs_pos:obs_pos+Nm, obs_pos:obs_pos+Nm] = np.eye(Nm) * 1e-14\n",
    "                obs_pos += Nm\n",
    "            \n",
    "            # Quarterly measurement noise (even more extreme precision)\n",
    "            if is_quarter_end and q_idx >= 0 and q_idx < YQ.shape[0]:\n",
    "                R[obs_pos:obs_pos+Nq, obs_pos:obs_pos+Nq] = np.eye(Nq) * 1e-12\n",
    "                obs_pos += Nq\n",
    "                \n",
    "                # VAR-to-latent constraint noise (extremely low)\n",
    "                R[obs_pos:obs_pos+Nq, obs_pos:obs_pos+Nq] = np.eye(Nq) * 1e-14\n",
    "                obs_pos += Nq\n",
    "            \n",
    "            # Add VAR-latent alignment constraints outside month/quarter end if included\n",
    "            if not monthly_constraints_added and t % 5 == 0:\n",
    "                R[obs_pos:obs_pos+Nm, obs_pos:obs_pos+Nm] = np.eye(Nm) * 1e-12\n",
    "                obs_pos += Nm\n",
    "                \n",
    "            if not quarterly_constraints_added and t % 10 == 0:\n",
    "                R[obs_pos:obs_pos+Nq, obs_pos:obs_pos+Nq] = np.eye(Nq) * 1e-12\n",
    "                obs_pos += Nq\n",
    "            \n",
    "            # UPDATE STEP WITH NUMERICAL STABILITY\n",
    "            # ------------------------------\n",
    "            y_hat = H @ a_pred\n",
    "            nu = y - y_hat  # Innovation\n",
    "            \n",
    "            # Innovation covariance - with careful regularization\n",
    "            S = H @ P_pred @ H.T + R\n",
    "            S = 0.5 * (S + S.T)  # Ensure perfect symmetry\n",
    "            \n",
    "            # Add regularization more safely\n",
    "            S_reg = S.copy()\n",
    "            try:\n",
    "                # Use eigvalsh for symmetric matrices which returns real eigenvalues\n",
    "                eig_vals = np.linalg.eigvalsh(S)\n",
    "                min_eig = np.min(eig_vals)\n",
    "                if min_eig < 1e-10:\n",
    "                    S_reg += np.eye(S.shape[0]) * (1e-10 - min_eig)\n",
    "            except:\n",
    "                # Fallback to simple regularization if eigvalsh fails\n",
    "                S_reg += np.eye(S.shape[0]) * 1e-8\n",
    "                if j == 0 and t < 10:\n",
    "                    print(f\"Warning: Using diagonal regularization for S at t={t}\")\n",
    "            \n",
    "            try:\n",
    "                # Kalman gain\n",
    "                K = P_pred @ H.T @ invert_matrix(S_reg)\n",
    "                \n",
    "                # Update state and covariance\n",
    "                a_t = a_pred + K @ nu\n",
    "                P_t = P_pred - K @ H @ P_pred\n",
    "                \n",
    "                # Force symmetry more carefully\n",
    "                P_t = 0.5 * (P_t + P_t.T)  # Ensure perfect symmetry\n",
    "                \n",
    "                # Force positive definiteness more robustly\n",
    "                try:\n",
    "                    # Use eigvalsh for symmetric matrices\n",
    "                    eig_vals = np.linalg.eigvalsh(P_t)\n",
    "                    min_eig = np.min(eig_vals)\n",
    "                    if min_eig < 1e-8:\n",
    "                        P_t += np.eye(P_t.shape[0]) * (1e-8 - min_eig)\n",
    "                except:\n",
    "                    # If eigvalsh fails, use a more brute-force approach\n",
    "                    P_t += np.eye(P_t.shape[0]) * 1e-6\n",
    "                    if j == 0 and t < 10:\n",
    "                        print(f\"Warning: Using diagonal regularization for P_t at t={t}\")\n",
    "                \n",
    "                # ENHANCED MEASUREMENT EQUATION ENFORCEMENT\n",
    "                # ------------------------------------------------\n",
    "                \n",
    "                # Month-end constraint enforcement using the measurement equation\n",
    "                if is_month_end and m_idx >= 0 and m_idx < YM.shape[0]:\n",
    "                    for m in range(Nm):\n",
    "                        # Get observed monthly value\n",
    "                        m_obs = YM[m_idx, m]\n",
    "                        var_block_idx = Nw + m\n",
    "                        \n",
    "                        # 1. First let's set the VAR block variable to match observation with high precision\n",
    "                        # This is done through a \"phantom\" observation using the Kalman update\n",
    "                        H_phantom = np.zeros((1, nstate))\n",
    "                        H_phantom[0, var_block_idx] = 1.0\n",
    "                        y_phantom = np.array([m_obs])\n",
    "                        R_phantom = np.array([[1e-12]])  # Very low measurement noise\n",
    "                        \n",
    "                        # Kalman gain for this phantom observation\n",
    "                        S_phantom = H_phantom @ P_t @ H_phantom.T + R_phantom\n",
    "                        K_phantom = P_t @ H_phantom.T @ np.linalg.inv(S_phantom)\n",
    "                        \n",
    "                        # Apply update\n",
    "                        a_t = a_t + K_phantom @ (y_phantom - H_phantom @ a_t)\n",
    "                        P_t = P_t - K_phantom @ H_phantom @ P_t\n",
    "                        \n",
    "                        # 2. Now enforce the temporal aggregation constraint with high precision\n",
    "                        # Build measurement matrix for aggregation\n",
    "                        H_agg = np.zeros((1, nstate))\n",
    "                        for w in range(rmw):\n",
    "                            state_idx = monthly_start + w*Nm + m\n",
    "                            if self.temp_agg == 'mean':\n",
    "                                H_agg[0, state_idx] = 1.0/rmw\n",
    "                            else:  # 'sum'\n",
    "                                H_agg[0, state_idx] = 1.0\n",
    "                        \n",
    "                        # Use phantom observation for aggregation\n",
    "                        y_agg = np.array([m_obs])\n",
    "                        R_agg = np.array([[1e-12]])  # Very low measurement noise\n",
    "                        \n",
    "                        # Kalman gain for aggregation\n",
    "                        S_agg = H_agg @ P_t @ H_agg.T + R_agg\n",
    "                        K_agg = P_t @ H_agg.T @ np.linalg.inv(S_agg)\n",
    "                        \n",
    "                        # Apply update\n",
    "                        a_t = a_t + K_agg @ (y_agg - H_agg @ a_t)\n",
    "                        P_t = P_t - K_agg @ H_agg @ P_t\n",
    "                        \n",
    "                        # 3. Enforce first-week alignment with VAR block\n",
    "                        H_align = np.zeros((1, nstate))\n",
    "                        H_align[0, var_block_idx] = 1.0  # VAR block\n",
    "                        H_align[0, monthly_start + m] = -1.0  # First week\n",
    "                        \n",
    "                        y_align = np.array([0.0])  # Zero difference\n",
    "                        R_align = np.array([[1e-12]])\n",
    "                        \n",
    "                        # Kalman gain for alignment\n",
    "                        S_align = H_align @ P_t @ H_align.T + R_align\n",
    "                        K_align = P_t @ H_align.T @ np.linalg.inv(S_align)\n",
    "                        \n",
    "                        # Apply update\n",
    "                        a_t = a_t + K_align @ (y_align - H_align @ a_t)\n",
    "                        P_t = P_t - K_align @ H_align @ P_t\n",
    "                        \n",
    "                        # 4. Apply value clipping afterward to prevent extreme values\n",
    "                        threshold = 3.0\n",
    "                        for w in range(rmw):\n",
    "                            state_idx = monthly_start + w*Nm + m\n",
    "                            if np.isnan(a_t[state_idx]) or np.isinf(a_t[state_idx]) or abs(a_t[state_idx]) > threshold:\n",
    "                                # Use a more conservative value but preserve some variability\n",
    "                                pattern_factor = 0.95 + 0.1 * (w / (rmw-1))\n",
    "                                a_t[state_idx] = np.sign(a_t[state_idx]) * min(threshold, abs(m_obs) * pattern_factor)\n",
    "                        \n",
    "                        # 5. Verify the constraint is reasonably enforced (for debugging)\n",
    "                        if self.temp_agg == 'mean':\n",
    "                            agg_value = np.mean([a_t[monthly_start + w*Nm + m] for w in range(rmw)])\n",
    "                        else:\n",
    "                            agg_value = np.sum([a_t[monthly_start + w*Nm + m] for w in range(rmw)])\n",
    "                        \n",
    "                        # Print verification for first few draws\n",
    "                        if j == 0 and t < 10:\n",
    "                            error = abs(agg_value - m_obs)\n",
    "                            print(f\"  Month {m_idx+1}, Var {m+1}: Target={m_obs:.8f}, Achieved={agg_value:.8f}, Error={error:.10f}\")\n",
    "                \n",
    "                # Quarter-end constraint enforcement using measurement equation - similar approach\n",
    "                if is_quarter_end and q_idx >= 0 and q_idx < YQ.shape[0]:\n",
    "                    for q in range(Nq):\n",
    "                        # Get observed quarterly value\n",
    "                        q_obs = YQ[q_idx, q]\n",
    "                        var_block_idx = Nw + Nm + q\n",
    "                        \n",
    "                        # 1. Set VAR block variable with high precision\n",
    "                        H_phantom = np.zeros((1, nstate))\n",
    "                        H_phantom[0, var_block_idx] = 1.0\n",
    "                        y_phantom = np.array([q_obs])\n",
    "                        R_phantom = np.array([[1e-12]])\n",
    "                        \n",
    "                        # Kalman gain for phantom observation\n",
    "                        S_phantom = H_phantom @ P_t @ H_phantom.T + R_phantom\n",
    "                        K_phantom = P_t @ H_phantom.T @ np.linalg.inv(S_phantom)\n",
    "                        \n",
    "                        # Apply update\n",
    "                        a_t = a_t + K_phantom @ (y_phantom - H_phantom @ a_t)\n",
    "                        P_t = P_t - K_phantom @ H_phantom @ P_t\n",
    "                        \n",
    "                        # 2. Enforce temporal aggregation constraint\n",
    "                        H_agg = np.zeros((1, nstate))\n",
    "                        for w in range(rqw):\n",
    "                            state_idx = quarterly_start + w*Nq + q\n",
    "                            if self.temp_agg == 'mean':\n",
    "                                H_agg[0, state_idx] = 1.0/rqw\n",
    "                            else:  # 'sum'\n",
    "                                H_agg[0, state_idx] = 1.0\n",
    "                        \n",
    "                        # Use phantom observation\n",
    "                        y_agg = np.array([q_obs])\n",
    "                        R_agg = np.array([[1e-12]])\n",
    "                        \n",
    "                        # Kalman gain for aggregation\n",
    "                        S_agg = H_agg @ P_t @ H_agg.T + R_agg\n",
    "                        K_agg = P_t @ H_agg.T @ np.linalg.inv(S_agg)\n",
    "                        \n",
    "                        # Apply update\n",
    "                        a_t = a_t + K_agg @ (y_agg - H_agg @ a_t)\n",
    "                        P_t = P_t - K_agg @ H_agg @ P_t\n",
    "                        \n",
    "                        # 3. Enforce first-week alignment with VAR block\n",
    "                        H_align = np.zeros((1, nstate))\n",
    "                        H_align[0, var_block_idx] = 1.0  # VAR block\n",
    "                        H_align[0, quarterly_start + q] = -1.0  # First week\n",
    "                        \n",
    "                        y_align = np.array([0.0])  # Zero difference\n",
    "                        R_align = np.array([[1e-12]])\n",
    "                        \n",
    "                        # Kalman gain for alignment\n",
    "                        S_align = H_align @ P_t @ H_align.T + R_align\n",
    "                        K_align = P_t @ H_align.T @ np.linalg.inv(S_align)\n",
    "                        \n",
    "                        # Apply update\n",
    "                        a_t = a_t + K_align @ (y_align - H_align @ a_t)\n",
    "                        P_t = P_t - K_align @ H_align @ P_t\n",
    "                        \n",
    "                        # 4. Apply value clipping to prevent extremes\n",
    "                        threshold = 3.0\n",
    "                        for w in range(rqw):\n",
    "                            state_idx = quarterly_start + w*Nq + q\n",
    "                            if np.isnan(a_t[state_idx]) or np.isinf(a_t[state_idx]) or abs(a_t[state_idx]) > threshold:\n",
    "                                # Use conservative value but preserve some variability\n",
    "                                pattern_factor = 0.95 + 0.1 * np.sin(np.pi * w / rqw)\n",
    "                                a_t[state_idx] = np.sign(a_t[state_idx]) * min(threshold, abs(q_obs) * pattern_factor)\n",
    "                        \n",
    "                        # 5. Verify constraint (for debugging)\n",
    "                        if self.temp_agg == 'mean':\n",
    "                            agg_value = np.mean([a_t[quarterly_start + w*Nq + q] for w in range(rqw)])\n",
    "                        else:\n",
    "                            agg_value = np.sum([a_t[quarterly_start + w*Nq + q] for w in range(rqw)])\n",
    "                        \n",
    "                        # Print verification for first few draws\n",
    "                        if j == 0 and t < 10:\n",
    "                            error = abs(agg_value - q_obs)\n",
    "                            print(f\"  Quarter {q_idx+1}, Var {q+1}: Target={q_obs:.8f}, Achieved={agg_value:.8f}, Error={error:.10f}\")\n",
    "                \n",
    "                # ENHANCED VALUE CLAMPING\n",
    "                # Apply global state value clipping\n",
    "                for i in range(nstate):\n",
    "                    # More aggressive clipping for latent states\n",
    "                    if i >= monthly_start:\n",
    "                        if np.isnan(a_t[i]) or np.isinf(a_t[i]):\n",
    "                            a_t[i] = 0.0  # Reset to zero if NaN or Inf\n",
    "                        elif abs(a_t[i]) > 3.0:  # Stricter threshold\n",
    "                            a_t[i] = np.sign(a_t[i]) * 3.0  # Clip to ±3.0\n",
    "                            \n",
    "                    # Standard clipping for VAR block\n",
    "                    else:\n",
    "                        if np.isnan(a_t[i]) or np.isinf(a_t[i]):\n",
    "                            a_t[i] = 0.0\n",
    "                        elif abs(a_t[i]) > 5.0:\n",
    "                            a_t[i] = np.sign(a_t[i]) * 5.0\n",
    "                \n",
    "                # ADDITIONAL GLOBAL STATE MONITORING\n",
    "                # Periodically scan and reset problematic states\n",
    "                if t % 10 == 0:\n",
    "                    # Check for any remaining extreme values or instabilities\n",
    "                    for i in range(nstate):\n",
    "                        if abs(a_t[i]) > 2.0 and i >= monthly_start:\n",
    "                            # For latent states, set to conservative default if still extreme\n",
    "                            if i < quarterly_start:  # Monthly latent\n",
    "                                m = (i - monthly_start) % Nm\n",
    "                                w = (i - monthly_start) // Nm\n",
    "                                if m_idx >= 0 and m_idx < YM.shape[0]:\n",
    "                                    # Set to monthly value with small deviation\n",
    "                                    m_val = YM[m_idx, m]\n",
    "                                    a_t[i] = m_val * (0.95 + 0.1 * w / rmw)\n",
    "                                else:\n",
    "                                    a_t[i] = 0.5  # Conservative default\n",
    "                            else:  # Quarterly latent\n",
    "                                q = (i - quarterly_start) % Nq\n",
    "                                w = (i - quarterly_start) // Nq\n",
    "                                if q_idx >= 0 and q_idx < YQ.shape[0]:\n",
    "                                    # Set to quarterly value with small deviation\n",
    "                                    q_val = YQ[q_idx, q]\n",
    "                                    a_t[i] = q_val * (0.95 + 0.1 * w / rqw)\n",
    "                                else:\n",
    "                                    a_t[i] = 0.5\n",
    "                                \n",
    "                            # Reduce uncertainty for reset states\n",
    "                            P_t[i, i] = 1e-6\n",
    "                \n",
    "            except np.linalg.LinAlgError as e:\n",
    "                if j == 0:\n",
    "                    print(f\"Warning: Matrix inversion failed at t={t}. Using prediction only. Error: {str(e)}\")\n",
    "                a_t = a_pred\n",
    "                P_t = P_pred\n",
    "                \n",
    "                # Apply value clamping even when falling back to prediction\n",
    "                threshold = 5.0\n",
    "                for i in range(len(a_t)):\n",
    "                    if np.isnan(a_t[i]) or np.isinf(a_t[i]) or abs(a_t[i]) > threshold:\n",
    "                        a_t[i] = threshold * np.sign(a_t[i]) if a_t[i] != 0 else 0.001\n",
    "            \n",
    "            # Store filtered state and covariance\n",
    "            a_filtered[t] = a_t\n",
    "            P_filtered[t] = P_t\n",
    "        \n",
    "        # KALMAN SMOOTHER\n",
    "        # -------------\n",
    "        \n",
    "        # Initialize smoother with last filtered state\n",
    "        a_smooth = np.zeros((nobs, nstate))\n",
    "        P_smooth = np.zeros((nobs, nstate, nstate))\n",
    "        \n",
    "        # Last state is the same for filtered and smoothed\n",
    "        a_smooth[-1] = a_filtered[-1]\n",
    "        P_smooth[-1] = P_filtered[-1]\n",
    "        \n",
    "        try:\n",
    "            # Force symmetry and positive-definiteness of P_smooth[-1] before Cholesky\n",
    "            P_smooth[-1] = 0.5 * (P_smooth[-1] + P_smooth[-1].T)  # Ensure symmetry\n",
    "            \n",
    "            try:\n",
    "                # Check and fix eigenvalues\n",
    "                eig_vals = np.linalg.eigvalsh(P_smooth[-1])\n",
    "                min_eig = np.min(eig_vals)\n",
    "                if min_eig < 1e-8:\n",
    "                    P_smooth[-1] += np.eye(P_smooth[-1].shape[0]) * (1e-8 - min_eig)\n",
    "            except:\n",
    "                # Fallback to simple regularization\n",
    "                P_smooth[-1] += np.eye(P_smooth[-1].shape[0]) * 1e-6\n",
    "                if j == 0:\n",
    "                    print(\"Warning: Using diagonal regularization for P_smooth[-1]\")\n",
    "            \n",
    "            # Draw the last state\n",
    "            Pchol = cholcovOrEigendecomp(P_smooth[-1])\n",
    "            a_draw = a_smooth[-1] + Pchol @ np.random.standard_normal(nstate)\n",
    "            \n",
    "            # Apply value clamping to the draw - more aggressive for latent states\n",
    "            threshold_var = 5.0  # VAR block\n",
    "            threshold_latent = 3.0  # Latent states\n",
    "            for i in range(len(a_draw)):\n",
    "                if np.isnan(a_draw[i]) or np.isinf(a_draw[i]):\n",
    "                    a_draw[i] = a_smooth[-1][i]  # Fall back to smoothed value\n",
    "                elif i >= monthly_start:  # Latent states\n",
    "                    if abs(a_draw[i]) > threshold_latent:\n",
    "                        a_draw[i] = np.sign(a_draw[i]) * threshold_latent\n",
    "                else:  # VAR block\n",
    "                    if abs(a_draw[i]) > threshold_var:\n",
    "                        a_draw[i] = np.sign(a_draw[i]) * threshold_var\n",
    "            \n",
    "            # Final check for aggregate constraint on last state\n",
    "            last_week_idx = T0 + nobs - 1\n",
    "            last_month_idx = last_week_idx // rmw\n",
    "            last_quarter_idx = last_week_idx // rqw\n",
    "            \n",
    "            # Check if this is month-end\n",
    "            is_month_end = ((last_week_idx + 1) % rmw == 0)\n",
    "            if is_month_end and last_month_idx < YM.shape[0]:\n",
    "                for m in range(Nm):\n",
    "                    # First enforce VAR block to match observed value\n",
    "                    var_block_idx = Nw + m\n",
    "                    m_obs = YM[last_month_idx, m]\n",
    "                    a_draw[var_block_idx] = m_obs\n",
    "                    \n",
    "                    # Now enforce latent state aggregation using Kalman update approach\n",
    "                    H_agg = np.zeros((1, nstate))\n",
    "                    for w in range(rmw):\n",
    "                        state_idx = monthly_start + w*Nm + m\n",
    "                        if self.temp_agg == 'mean':\n",
    "                            H_agg[0, state_idx] = 1.0/rmw\n",
    "                        else:  # 'sum'\n",
    "                            H_agg[0, state_idx] = 1.0\n",
    "                    \n",
    "                    # Check current aggregation\n",
    "                    m_values = np.array([a_draw[monthly_start + w*Nm + m] for w in range(rmw)])\n",
    "                    if self.temp_agg == 'mean':\n",
    "                        agg_value = np.mean(m_values)\n",
    "                    else:\n",
    "                        agg_value = np.sum(m_values)\n",
    "                    \n",
    "                    # If aggregation is off by more than a small tolerance, adjust the pattern\n",
    "                    if abs(agg_value - m_obs) > 1e-6:\n",
    "                        if self.temp_agg == 'mean':\n",
    "                            # Shift pattern to match target mean while preserving shape\n",
    "                            adjustment = m_obs - agg_value\n",
    "                            for w in range(rmw):\n",
    "                                a_draw[monthly_start + w*Nm + m] += adjustment\n",
    "                        else:  # 'sum'\n",
    "                            if abs(agg_value) > 1e-10:  # Avoid division by zero\n",
    "                                # Scale pattern to match target sum while preserving shape\n",
    "                                scale = m_obs / agg_value\n",
    "                                scale = np.clip(scale, 0.5, 2.0)  # Limit scale factor\n",
    "                                for w in range(rmw):\n",
    "                                    a_draw[monthly_start + w*Nm + m] *= scale\n",
    "                            else:\n",
    "                                # If near zero, distribute evenly\n",
    "                                for w in range(rmw):\n",
    "                                    a_draw[monthly_start + w*Nm + m] = m_obs / rmw\n",
    "            \n",
    "            # Check if this is quarter-end\n",
    "            is_quarter_end = ((last_week_idx + 1) % rqw == 0)\n",
    "            if is_quarter_end and last_quarter_idx < YQ.shape[0]:\n",
    "                for q in range(Nq):\n",
    "                    # First enforce VAR block to match observed value\n",
    "                    var_block_idx = Nw + Nm + q\n",
    "                    q_obs = YQ[last_quarter_idx, q]\n",
    "                    a_draw[var_block_idx] = q_obs\n",
    "                    \n",
    "                    # Now enforce latent state aggregation using Kalman update approach\n",
    "                    H_agg = np.zeros((1, nstate))\n",
    "                    for w in range(rqw):\n",
    "                        state_idx = quarterly_start + w*Nq + q\n",
    "                        if self.temp_agg == 'mean':\n",
    "                            H_agg[0, state_idx] = 1.0/rqw\n",
    "                        else:  # 'sum'\n",
    "                            H_agg[0, state_idx] = 1.0\n",
    "                    \n",
    "                    # Check current aggregation\n",
    "                    q_values = np.array([a_draw[quarterly_start + w*Nq + q] for w in range(rqw)])\n",
    "                    if self.temp_agg == 'mean':\n",
    "                        agg_value = np.mean(q_values)\n",
    "                    else:\n",
    "                        agg_value = np.sum(q_values)\n",
    "                    \n",
    "                    # If aggregation is off by more than a small tolerance, adjust the pattern\n",
    "                    if abs(agg_value - q_obs) > 1e-6:\n",
    "                        if self.temp_agg == 'mean':\n",
    "                            # Shift pattern to match target mean while preserving shape\n",
    "                            adjustment = q_obs - agg_value\n",
    "                            for w in range(rqw):\n",
    "                                a_draw[quarterly_start + w*Nq + q] += adjustment\n",
    "                        else:  # 'sum'\n",
    "                            if abs(agg_value) > 1e-10:  # Avoid division by zero\n",
    "                                # Scale pattern to match target sum while preserving shape\n",
    "                                scale = q_obs / agg_value\n",
    "                                scale = np.clip(scale, 0.75, 1.5)  # Tighter limits for quarterly\n",
    "                                for w in range(rqw):\n",
    "                                    a_draw[quarterly_start + w*Nq + q] *= scale\n",
    "                            else:\n",
    "                                # If near zero, distribute evenly\n",
    "                                for w in range(rqw):\n",
    "                                    a_draw[quarterly_start + w*Nq + q] = q_obs / rqw\n",
    "            \n",
    "            # Store the draw\n",
    "            a_draws[j, -1] = a_draw\n",
    "            \n",
    "            # Backward recursion\n",
    "            for t in range(nobs-2, -1, -1):\n",
    "                # Get filtered state and covariance\n",
    "                a_filt = a_filtered[t]\n",
    "                P_filt = P_filtered[t]\n",
    "                \n",
    "                # Predict one step ahead\n",
    "                a_pred = F @ a_filt + c.flatten()\n",
    "                P_pred = F @ P_filt @ F.T + Q\n",
    "                P_pred = 0.5 * (P_pred + P_pred.T)  # Ensure symmetry\n",
    "                \n",
    "                try:\n",
    "                    # Add regularization to P_pred before inversion if needed\n",
    "                    P_pred_reg = P_pred.copy()\n",
    "                    try:\n",
    "                        eig_vals = np.linalg.eigvalsh(P_pred)\n",
    "                        min_eig = np.min(eig_vals)\n",
    "                        if min_eig < 1e-8:\n",
    "                            P_pred_reg += np.eye(P_pred.shape[0]) * (1e-8 - min_eig)\n",
    "                    except:\n",
    "                        # Fallback to simple regularization\n",
    "                        P_pred_reg += np.eye(P_pred.shape[0]) * 1e-6\n",
    "                    \n",
    "                    # Smoothing gain\n",
    "                    J_t = P_filt @ F.T @ invert_matrix(P_pred_reg)\n",
    "                    \n",
    "                    # Smoothed mean and covariance\n",
    "                    a_smooth_t = a_filt + J_t @ (a_draw - a_pred)\n",
    "                    P_smooth_t = P_filt - J_t @ (P_pred - P_smooth[t+1]) @ J_t.T\n",
    "                    P_smooth_t = 0.5 * (P_smooth_t + P_smooth_t.T)  # Ensure symmetry\n",
    "                    \n",
    "                    # Force positive definiteness\n",
    "                    try:\n",
    "                        eig_vals = np.linalg.eigvalsh(P_smooth_t)\n",
    "                        min_eig = np.min(eig_vals)\n",
    "                        if min_eig < 1e-8:\n",
    "                            P_smooth_t += np.eye(P_smooth_t.shape[0]) * (1e-8 - min_eig)\n",
    "                    except:\n",
    "                        # Fallback\n",
    "                        P_smooth_t += np.eye(P_smooth_t.shape[0]) * 1e-6\n",
    "                    \n",
    "                    # Store smoothed state and covariance\n",
    "                    a_smooth[t] = a_smooth_t\n",
    "                    P_smooth[t] = P_smooth_t\n",
    "                    \n",
    "                    # Draw state\n",
    "                    Pchol = cholcovOrEigendecomp(P_smooth_t)\n",
    "                    a_draw = a_smooth_t + Pchol @ np.random.standard_normal(nstate)\n",
    "                    \n",
    "                    # Apply value clamping to the draw - more aggressive for latent states\n",
    "                    threshold_var = 5.0  # VAR block\n",
    "                    threshold_latent = 3.0  # Latent states\n",
    "                    for i in range(len(a_draw)):\n",
    "                        if np.isnan(a_draw[i]) or np.isinf(a_draw[i]):\n",
    "                            a_draw[i] = a_smooth_t[i]  # Fall back to smoothed value\n",
    "                        elif i >= monthly_start:  # Latent states\n",
    "                            if abs(a_draw[i]) > threshold_latent:\n",
    "                                a_draw[i] = np.sign(a_draw[i]) * threshold_latent\n",
    "                        else:  # VAR block\n",
    "                            if abs(a_draw[i]) > threshold_var:\n",
    "                                a_draw[i] = np.sign(a_draw[i]) * threshold_var\n",
    "                    \n",
    "                    # Check and enforce constraints for this period\n",
    "                    w_idx = T0 + t\n",
    "                    m_idx = w_idx // rmw\n",
    "                    q_idx = w_idx // rqw\n",
    "                    \n",
    "                    # Check if this is month-end\n",
    "                    is_month_end = ((w_idx + 1) % rmw == 0)\n",
    "                    if is_month_end and m_idx < YM.shape[0]:\n",
    "                        for m in range(Nm):\n",
    "                            # First enforce VAR block to match observed value\n",
    "                            var_block_idx = Nw + m\n",
    "                            m_obs = YM[m_idx, m]\n",
    "                            a_draw[var_block_idx] = m_obs\n",
    "                            \n",
    "                            # Now enforce latent state aggregation using Kalman update approach\n",
    "                            # Check current aggregation\n",
    "                            m_values = np.array([a_draw[monthly_start + w*Nm + m] for w in range(rmw)])\n",
    "                            if self.temp_agg == 'mean':\n",
    "                                agg_value = np.mean(m_values)\n",
    "                            else:\n",
    "                                agg_value = np.sum(m_values)\n",
    "                            \n",
    "                            # If aggregation is off by more than a small tolerance, adjust the pattern\n",
    "                            if abs(agg_value - m_obs) > 1e-6:\n",
    "                                if self.temp_agg == 'mean':\n",
    "                                    # Shift pattern to match target mean while preserving shape\n",
    "                                    adjustment = m_obs - agg_value\n",
    "                                    for w in range(rmw):\n",
    "                                        a_draw[monthly_start + w*Nm + m] += adjustment\n",
    "                                else:  # 'sum'\n",
    "                                    if abs(agg_value) > 1e-10:  # Avoid division by zero\n",
    "                                        # Scale pattern to match target sum while preserving shape\n",
    "                                        scale = m_obs / agg_value\n",
    "                                        scale = np.clip(scale, 0.5, 2.0)  # Limit scale factor\n",
    "                                        for w in range(rmw):\n",
    "                                            a_draw[monthly_start + w*Nm + m] *= scale\n",
    "                                    else:\n",
    "                                        # If near zero, distribute evenly\n",
    "                                        for w in range(rmw):\n",
    "                                            a_draw[monthly_start + w*Nm + m] = m_obs / rmw\n",
    "                    \n",
    "                    # Check if this is quarter-end\n",
    "                    is_quarter_end = ((w_idx + 1) % rqw == 0)\n",
    "                    if is_quarter_end and q_idx < YQ.shape[0]:\n",
    "                        for q in range(Nq):\n",
    "                            # First enforce VAR block to match observed value\n",
    "                            var_block_idx = Nw + Nm + q\n",
    "                            q_obs = YQ[q_idx, q]\n",
    "                            a_draw[var_block_idx] = q_obs\n",
    "                            \n",
    "                            # Now enforce latent state aggregation using Kalman update approach\n",
    "                            # Check current aggregation\n",
    "                            q_values = np.array([a_draw[quarterly_start + w*Nq + q] for w in range(rqw)])\n",
    "                            if self.temp_agg == 'mean':\n",
    "                                agg_value = np.mean(q_values)\n",
    "                            else:\n",
    "                                agg_value = np.sum(q_values)\n",
    "                            \n",
    "                            # If aggregation is off by more than a small tolerance, adjust the pattern\n",
    "                            if abs(agg_value - q_obs) > 1e-6:\n",
    "                                if self.temp_agg == 'mean':\n",
    "                                    # Shift pattern to match target mean while preserving shape\n",
    "                                    adjustment = q_obs - agg_value\n",
    "                                    for w in range(rqw):\n",
    "                                        a_draw[quarterly_start + w*Nq + q] += adjustment\n",
    "                                else:  # 'sum'\n",
    "                                    if abs(agg_value) > 1e-10:  # Avoid division by zero\n",
    "                                        # Scale pattern to match target sum while preserving shape\n",
    "                                        scale = q_obs / agg_value\n",
    "                                        scale = np.clip(scale, 0.75, 1.5)  # Tighter limits for quarterly\n",
    "                                        for w in range(rqw):\n",
    "                                            a_draw[quarterly_start + w*Nq + q] *= scale\n",
    "                                    else:\n",
    "                                        # If near zero, distribute evenly\n",
    "                                        for w in range(rqw):\n",
    "                                            a_draw[quarterly_start + w*Nq + q] = q_obs / rqw\n",
    "                    \n",
    "                    # Also enforce VAR-to-latent alignment for first week of each period\n",
    "                    if (w_idx % rmw == 0) and (w_idx // rmw) < YM.shape[0]:\n",
    "                        for m in range(Nm):\n",
    "                            # Force first week to match VAR block\n",
    "                            a_draw[monthly_start + m] = a_draw[Nw + m]\n",
    "                    \n",
    "                    if (w_idx % rqw == 0) and (w_idx // rqw) < YQ.shape[0]:\n",
    "                        for q in range(Nq):\n",
    "                            # Force first week to match VAR block\n",
    "                            a_draw[quarterly_start + q] = a_draw[Nw + Nm + q]\n",
    "                    \n",
    "                    # Store the draw\n",
    "                    a_draws[j, t] = a_draw\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    # Fallback for smoother error\n",
    "                    if j == 0:\n",
    "                        print(f\"Smoother error at t={t}: {str(e)}\")\n",
    "                    a_smooth[t] = a_filtered[t]\n",
    "                    P_smooth[t] = P_filtered[t]\n",
    "                    \n",
    "                    # Use filtered state with small noise but apply value clamping\n",
    "                    a_draws[j, t] = a_filtered[t] + np.random.standard_normal(nstate) * 1e-4\n",
    "                    \n",
    "                    # Apply value clamping\n",
    "                    threshold = 5.0\n",
    "                    for i in range(len(a_draws[j, t])):\n",
    "                        if np.isnan(a_draws[j, t, i]) or np.isinf(a_draws[j, t, i]) or abs(a_draws[j, t, i]) > threshold:\n",
    "                            a_draws[j, t, i] = threshold * np.sign(a_draws[j, t, i]) if a_draws[j, t, i] != 0 else 0.001\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Fallback for smoother initialization error\n",
    "            if j == 0:\n",
    "                print(f\"Smoother initialization error: {str(e)}\")\n",
    "            \n",
    "            # Copy filtered states but apply value clamping\n",
    "            for t in range(nobs):\n",
    "                a_draws[j, t] = a_filtered[t]\n",
    "                # Apply value clamping\n",
    "                threshold = 5.0\n",
    "                for i in range(len(a_draws[j, t])):\n",
    "                    if np.isnan(a_draws[j, t, i]) or np.isinf(a_draws[j, t, i]) or abs(a_draws[j, t, i]) > threshold:\n",
    "                        a_draws[j, t, i] = threshold * np.sign(a_draws[j, t, i]) if a_draws[j, t, i] != 0 else 0.001\n",
    "            \n",
    "        # FINAL VERIFICATION FOR THIS DRAW\n",
    "        # ------------------------------\n",
    "        \n",
    "        # Verify key constraints for debugging\n",
    "        if j == 0 or j == self.nsim - 1:\n",
    "            constraint_errors = 0\n",
    "            \n",
    "            # Check all month-ends\n",
    "            for t in range(nobs):\n",
    "                w_idx = T0 + t\n",
    "                # Check if this is month-end\n",
    "                if (w_idx + 1) % rmw == 0:\n",
    "                    m_idx = w_idx // rmw\n",
    "                    if m_idx < YM.shape[0]:\n",
    "                        for m in range(Nm):\n",
    "                            # Get latent states\n",
    "                            m_values = np.zeros(rmw)\n",
    "                            for w in range(rmw):\n",
    "                                m_values[w] = a_draws[j, t, monthly_start + w*Nm + m]\n",
    "                            \n",
    "                            # Check aggregation\n",
    "                            if self.temp_agg == 'mean':\n",
    "                                agg_value = np.mean(m_values)\n",
    "                            else:\n",
    "                                agg_value = np.sum(m_values)\n",
    "                            \n",
    "                            error = abs(agg_value - YM[m_idx, m])\n",
    "                            if error > 1e-6:\n",
    "                                constraint_errors += 1\n",
    "                                if constraint_errors <= 5:  # Limit output\n",
    "                                    print(f\"Draw {j}, Month {m_idx+1}, Var {m+1}: Agg={agg_value:.8f}, \"\n",
    "                                          f\"Target={YM[m_idx, m]:.8f}, Error={error:.8f}\")\n",
    "            \n",
    "            # Check all quarter-ends\n",
    "            for t in range(nobs):\n",
    "                w_idx = T0 + t\n",
    "                # Check if this is quarter-end\n",
    "                if (w_idx + 1) % rqw == 0:\n",
    "                    q_idx = w_idx // rqw\n",
    "                    if q_idx < YQ.shape[0]:\n",
    "                        for q in range(Nq):\n",
    "                            # Get latent states\n",
    "                            q_values = np.zeros(rqw)\n",
    "                            for w in range(rqw):\n",
    "                                q_values[w] = a_draws[j, t, quarterly_start + w*Nq + q]\n",
    "                            \n",
    "                            # Check aggregation\n",
    "                            if self.temp_agg == 'mean':\n",
    "                                agg_value = np.mean(q_values)\n",
    "                            else:\n",
    "                                agg_value = np.sum(q_values)\n",
    "                            \n",
    "                            error = abs(agg_value - YQ[q_idx, q])\n",
    "                            if error > 1e-6:\n",
    "                                constraint_errors += 1\n",
    "                                if constraint_errors <= 5:  # Limit output\n",
    "                                    print(f\"Draw {j}, Quarter {q_idx+1}, Var {q+1}: Agg={agg_value:.8f}, \"\n",
    "                                          f\"Target={YQ[q_idx, q]:.8f}, Error={error:.8f}\")\n",
    "            \n",
    "            if constraint_errors > 0:\n",
    "                print(f\"Draw {j}: Found {constraint_errors} constraint violations\")\n",
    "            else:\n",
    "                print(f\"Draw {j}: All aggregation constraints satisfied\")\n",
    "        \n",
    "        # CALCULATE VAR POSTERIOR USING ALL VARIABLES\n",
    "        # ---------------------------------------\n",
    "        \n",
    "        # Create a combined matrix of all variables for VAR estimation\n",
    "        combined_smooth = np.zeros((nobs, Ntotal))\n",
    "        \n",
    "        # Weekly variables (direct)\n",
    "        combined_smooth[:, :Nw] = a_draws[j, :, :Nw]\n",
    "        \n",
    "        # Monthly variables (from state vector)\n",
    "        combined_smooth[:, Nw:Nw+Nm] = a_draws[j, :, Nw:Nw+Nm]\n",
    "        \n",
    "        # Quarterly variables (from state vector)\n",
    "        combined_smooth[:, Nw+Nm:Ntotal] = a_draws[j, :, Nw+Nm:Ntotal]\n",
    "        \n",
    "        # Use the combined matrix for VAR estimation\n",
    "        YY = combined_smooth\n",
    "        \n",
    "        # Prepare lagged data for the VAR\n",
    "        Z = np.zeros((nobs, Ntotal * p))\n",
    "        for i in range(nobs):\n",
    "            for lag in range(p):\n",
    "                if i - lag >= 0:\n",
    "                    Z[i, lag*Ntotal:(lag+1)*Ntotal] = YY[i-lag]\n",
    "        \n",
    "        # Compute actual observations for Minnesota prior\n",
    "        nobs_ = YY.shape[0] - p  # Adjusted for lags\n",
    "        spec = np.hstack((p, p, self.nex, Ntotal, nobs_))  # Now using all variables (Ntotal)\n",
    "        \n",
    "        # Calculate dummy observations for the full VAR\n",
    "        YYact, YYdum, XXact, XXdum = calc_yyact(self.hyp, YY, spec)\n",
    "        \n",
    "        # Store simulation results for all variables\n",
    "        if (j % self.thining == 0):\n",
    "            j_temp = int(j/self.thining)\n",
    "            if j == 0:\n",
    "                # Initialize storage for all variables\n",
    "                YYactsim_list = [np.zeros((math.ceil((self.nsim)/self.thining), rmw, Ntotal))]\n",
    "                XXactsim_list = [np.zeros((math.ceil((self.nsim)/self.thining), rmw, Ntotal*p+1))]  # For all variables\n",
    "            \n",
    "            # Store the combined data\n",
    "            YYactsim_list[0][j_temp, :, :] = combined_smooth[-rmw:, :]\n",
    "            \n",
    "            # Create lagged data matrix for all variables\n",
    "            X_combined = np.zeros((rmw, Ntotal*p+1))\n",
    "            for i in range(rmw):\n",
    "                for lag in range(p):\n",
    "                    t_idx = nobs - rmw + i - lag\n",
    "                    if t_idx >= 0:\n",
    "                        X_combined[i, lag*Ntotal:(lag+1)*Ntotal] = combined_smooth[t_idx, :]\n",
    "            X_combined[:, -1] = 1.0  # Add constant\n",
    "            \n",
    "            XXactsim_list[0][j_temp, :, :] = X_combined\n",
    "        \n",
    "        # VAR POSTERIOR SAMPLING\n",
    "        # -------------------\n",
    "        \n",
    "        try:\n",
    "            # Standard VAR posterior calculations\n",
    "            Tdummy, n = YYdum.shape\n",
    "            n = int(n)\n",
    "            Tdummy = int(Tdummy)\n",
    "            Tobs, n = YYact.shape\n",
    "            X = np.vstack((XXact, XXdum))\n",
    "            Y = np.vstack((YYact, YYdum))\n",
    "            T = Tobs + Tdummy\n",
    "            \n",
    "            # Compute posterior parameters\n",
    "            vl, d, vr = np.linalg.svd(X, full_matrices=False)\n",
    "            vr = vr.T\n",
    "            di = 1/d\n",
    "            B = vl.T @ Y\n",
    "            xxi = (vr * np.tile(di.T, (Ntotal*p+1, 1)))\n",
    "            inv_x = xxi @ xxi.T\n",
    "            Phi_tilde = xxi @ B\n",
    "            \n",
    "            Sigma = (Y - X @ Phi_tilde).T @ (Y - X @ Phi_tilde)\n",
    "            \n",
    "            # Ensure Sigma is symmetric positive definite before inverse Wishart draw\n",
    "            Sigma = 0.5 * (Sigma + Sigma.T)\n",
    "            \n",
    "            try:\n",
    "                # Check and fix eigenvalues if needed\n",
    "                eig_vals = np.linalg.eigvalsh(Sigma)\n",
    "                min_eig = np.min(eig_vals)\n",
    "                if min_eig < 1e-8:\n",
    "                    Sigma += np.eye(Sigma.shape[0]) * (1e-8 - min_eig)\n",
    "            except:\n",
    "                # Fallback to simple regularization\n",
    "                Sigma += np.eye(Sigma.shape[0]) * 1e-6\n",
    "                if j == 0:\n",
    "                    print(\"Warning: Using diagonal regularization for Sigma\")\n",
    "            \n",
    "            # Draw from inverse Wishart for covariance matrix\n",
    "            sigma_w = invwishart.rvs(scale=Sigma, df=T-Ntotal*p-1)\n",
    "            \n",
    "            # Draw VAR coefficients and check stability\n",
    "            attempts = 0\n",
    "            while attempts < 1000:\n",
    "                try:\n",
    "                    # Compute Cholesky safely\n",
    "                    kron_matrix = np.kron(sigma_w, inv_x)\n",
    "                    kron_matrix = 0.5 * (kron_matrix + kron_matrix.T)  # Ensure symmetry\n",
    "                    \n",
    "                    try:\n",
    "                        # Check eigenvalues\n",
    "                        eig_vals = np.linalg.eigvalsh(kron_matrix)\n",
    "                        min_eig = np.min(eig_vals)\n",
    "                        if min_eig < 1e-8:\n",
    "                            kron_matrix += np.eye(kron_matrix.shape[0]) * (1e-8 - min_eig)\n",
    "                    except:\n",
    "                        # Fallback\n",
    "                        kron_matrix += np.eye(kron_matrix.shape[0]) * 1e-6\n",
    "                    \n",
    "                    sigma_chol = cholcovOrEigendecomp(kron_matrix)\n",
    "                    phi_new = np.squeeze(Phi_tilde.reshape(Ntotal*(Ntotal*p+1), 1, order=\"F\")) + sigma_chol @ np.random.standard_normal(sigma_chol.shape[0])\n",
    "                    Phi_w = phi_new.reshape(Ntotal*p+1, Ntotal, order=\"F\")\n",
    "                    \n",
    "                    # NEW: Apply regularization to prevent explosive estimates\n",
    "                    # Shrink coefficients for lagged variables toward zero\n",
    "                    for lag in range(1, p+1):\n",
    "                        lag_idx_start = (lag-1) * Ntotal\n",
    "                        lag_idx_end = lag * Ntotal\n",
    "                        shrinkage_factor = 0.95 ** lag  # More shrinkage for more distant lags\n",
    "                        Phi_w[lag_idx_start:lag_idx_end, :] *= shrinkage_factor\n",
    "\n",
    "                    # Constrain diagonal elements of first lag to reasonable range\n",
    "                    for i in range(Ntotal):\n",
    "                        # First lag diagonal elements shouldn't be too extreme\n",
    "                        if abs(Phi_w[i, i]) > 0.9:\n",
    "                            Phi_w[i, i] = 0.9 * np.sign(Phi_w[i, i])\n",
    "                    \n",
    "                    if not is_explosive(Phi_w, Ntotal, p):\n",
    "                        break\n",
    "                except Exception as e:\n",
    "                    if j == 0 and attempts == 0:\n",
    "                        print(f\"VAR coefficient sampling error: {str(e)}, retrying...\")\n",
    "                \n",
    "                attempts += 1\n",
    "            \n",
    "            if attempts == 1000:\n",
    "                explosive_counter += 1\n",
    "                print(f\"Explosive VAR detected {explosive_counter} times.\")\n",
    "                continue\n",
    "            \n",
    "            # Store posterior draws\n",
    "            if (j % self.thining == 0):\n",
    "                j_temp = int(j/self.thining)\n",
    "                Sigmap[j_temp, :, :] = sigma_w\n",
    "                Phip[j_temp, :, :] = Phi_w\n",
    "                Cons[j_temp, :] = Phi_w[-1, :]\n",
    "                valid_draws.append(j_temp)\n",
    "            \n",
    "            # Update transition matrix for next iteration - now for all variables\n",
    "            F[:Ntotal, :Ntotal*p] = Phi_w[:-1, :].T  # All VAR coefficients (excluding constant)\n",
    "            c[:Ntotal] = np.atleast_2d(Phi_w[-1, :]).T  # Constants for all variables\n",
    "            \n",
    "            # Remember to keep the block structure intact for variable lags\n",
    "            for i in range(p-1):\n",
    "                F[Ntotal*(i+1):Ntotal*(i+2), Ntotal*i:Ntotal*(i+1)] = np.eye(Ntotal)\n",
    "            \n",
    "            # Monthly block shifting for latent states\n",
    "            for i in range(rmw-1):\n",
    "                src_pos = monthly_start + i*Nm\n",
    "                dest_pos = monthly_start + (i+1)*Nm\n",
    "                F[dest_pos:dest_pos+Nm, src_pos:src_pos+Nm] = np.eye(Nm)\n",
    "            \n",
    "            # Quarterly block shifting for latent states\n",
    "            for i in range(rqw-1):\n",
    "                src_pos = quarterly_start + i*Nq\n",
    "                dest_pos = quarterly_start + (i+1)*Nq\n",
    "                F[dest_pos:dest_pos+Nq, src_pos:src_pos+Nq] = np.eye(Nq)\n",
    "            \n",
    "            # Weekly influence for latent states\n",
    "            F[monthly_start:monthly_start+Nm, :Nw] = 0.1 * np.eye(Nm, Nw)\n",
    "            F[quarterly_start:quarterly_start+Nq, :Nw] = 0.05 * np.eye(Nq, Nw)\n",
    "            \n",
    "            # Update system covariance\n",
    "            Q[:Ntotal, :Ntotal] = sigma_w\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Period 1: week_idx=12, quarter_end=False, month_end=False\n",
      "Period 2: week_idx=13, quarter_end=False, month_end=False\n",
      "Period 3: week_idx=14, quarter_end=False, month_end=False\n",
      "Period 4: week_idx=15, quarter_end=False, month_end=True\n",
      "  Monthly observation: [ 0.00543815  0.00273287 -0.00063385]\n",
      "  Month 4, Var 1: Target=0.00543815, Achieved=0.00543815, Error=0.0000000004\n",
      "  Month 4, Var 2: Target=0.00273287, Achieved=0.00273287, Error=0.0000000002\n",
      "  Month 4, Var 3: Target=-0.00063385, Achieved=-0.00063385, Error=0.0000000001\n",
      "Period 5: week_idx=16, quarter_end=False, month_end=False\n",
      "  Month 5, Var 1: Target=-0.00016291, Achieved=-0.00016291, Error=0.0000000001\n",
      "  Month 5, Var 2: Target=-0.00238576, Achieved=-0.00238576, Error=0.0000000001\n",
      "  Month 5, Var 3: Target=-0.00158969, Achieved=-0.00158969, Error=0.0000000001\n",
      "Draw 0: All aggregation constraints satisfied\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "'continue' not properly in loop (<ipython-input-9-0d9e7ff8e7af>, line 918)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 918\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mcontinue\u001b[39m\n    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m 'continue' not properly in loop\n"
     ]
    }
   ],
   "source": [
    "        if j > 0:\n",
    "            a_t = a_draws[j-1, -1]\n",
    "            P_t = P_filtered[-1]\n",
    "        \n",
    "        # Kalman filter loop through all periods\n",
    "        for t in range(nobs):\n",
    "            # Current week index\n",
    "            w_idx = T0 + t\n",
    "            \n",
    "            # PREDICTION STEP\n",
    "            # --------------\n",
    "            a_pred = F @ a_t + c.flatten()\n",
    "            P_pred = F @ P_t @ F.T + Q\n",
    "            P_pred = 0.5 * (P_pred + P_pred.T)  # Ensure perfect symmetry\n",
    "            \n",
    "            # DETERMINE AVAILABLE OBSERVATIONS\n",
    "            # -----------------------------\n",
    "            \n",
    "            # Check which observations are available at this period\n",
    "            is_quarter_end = q_obs_periods[w_idx] if w_idx < len(q_obs_periods) else False\n",
    "            is_month_end = m_obs_periods[w_idx] if w_idx < len(m_obs_periods) else False\n",
    "            \n",
    "            # Get indices for the observation vectors\n",
    "            q_idx = w_idx // rqw if is_quarter_end else -1\n",
    "            m_idx = w_idx // rmw if is_month_end else -1\n",
    "            \n",
    "            # Debug output for first few periods\n",
    "            if j == 0 and t < 5:\n",
    "                print(f\"Period {t+1}: week_idx={w_idx}, quarter_end={is_quarter_end}, month_end={is_month_end}\")\n",
    "                if is_quarter_end:\n",
    "                    print(f\"  Quarterly observation: {YQ[q_idx]}\")\n",
    "                if is_month_end:\n",
    "                    print(f\"  Monthly observation: {YM[m_idx]}\")\n",
    "            \n",
    "            # BUILD ENHANCED MEASUREMENT MATRICES AND OBSERVATION VECTOR\n",
    "            # -----------------------------------------------------\n",
    "            \n",
    "            # Start with weekly observations (always available)\n",
    "            H_matrices = [H_w]\n",
    "            y_obs = [YW[w_idx]]\n",
    "            \n",
    "            # Add monthly observations if available\n",
    "            monthly_constraints_added = False\n",
    "            if is_month_end and m_idx >= 0 and m_idx < YM.shape[0]:\n",
    "                H_matrices.append(H_m)\n",
    "                y_obs.append(YM[m_idx])\n",
    "                \n",
    "                # Always add the constraint that links VAR block to latent states\n",
    "                H_matrices.append(H_m_constraint)\n",
    "                y_obs.append(np.zeros(Nm))  # Zero difference means equality constraint\n",
    "                monthly_constraints_added = True\n",
    "            \n",
    "            # Add quarterly observations if available\n",
    "            quarterly_constraints_added = False\n",
    "            if is_quarter_end and q_idx >= 0 and q_idx < YQ.shape[0]:\n",
    "                H_matrices.append(H_q)\n",
    "                y_obs.append(YQ[q_idx])\n",
    "                \n",
    "                # Always add the constraint that links VAR block to latent states\n",
    "                H_matrices.append(H_q_constraint)\n",
    "                y_obs.append(np.zeros(Nq))  # Zero difference means equality constraint\n",
    "                quarterly_constraints_added = True\n",
    "            \n",
    "            # Also enforce VAR-latent alignment constraints at every period\n",
    "            # (not just at month/quarter end)\n",
    "            if not monthly_constraints_added and t % 5 == 0:  # Every 5 periods to avoid too much constraint\n",
    "                H_matrices.append(H_m_constraint)\n",
    "                y_obs.append(np.zeros(Nm))\n",
    "            \n",
    "            if not quarterly_constraints_added and t % 10 == 0:  # Less frequent for quarterly\n",
    "                H_matrices.append(H_q_constraint)\n",
    "                y_obs.append(np.zeros(Nq))\n",
    "            \n",
    "            # Combined measurement matrix and observation vector\n",
    "            H = np.vstack(H_matrices)\n",
    "            y = np.concatenate(y_obs)\n",
    "            \n",
    "            # DIFFERENT MEASUREMENT NOISE BY FREQUENCY - EXTREMELY PRECISE FOR CONSTRAINTS\n",
    "            # ---------------------------------------------------------------------\n",
    "            \n",
    "            # Create measurement noise matrix with precision scaled by frequency\n",
    "            R = np.zeros((len(y), len(y)))\n",
    "            \n",
    "            # Current position in the observation vector\n",
    "            obs_pos = 0\n",
    "            \n",
    "            # Weekly measurement noise (standard precision)\n",
    "            R[obs_pos:obs_pos+Nw, obs_pos:obs_pos+Nw] = np.eye(Nw) * 1e-3\n",
    "            obs_pos += Nw\n",
    "            \n",
    "            # Monthly measurement noise (extreme precision to enforce constraint)\n",
    "            if is_month_end and m_idx >= 0 and m_idx < YM.shape[0]:\n",
    "                R[obs_pos:obs_pos+Nm, obs_pos:obs_pos+Nm] = np.eye(Nm) * 1e-12\n",
    "                obs_pos += Nm\n",
    "                \n",
    "                # VAR-to-latent constraint noise (extremely low)\n",
    "                R[obs_pos:obs_pos+Nm, obs_pos:obs_pos+Nm] = np.eye(Nm) * 1e-14\n",
    "                obs_pos += Nm\n",
    "            \n",
    "            # Quarterly measurement noise (even more extreme precision)\n",
    "            if is_quarter_end and q_idx >= 0 and q_idx < YQ.shape[0]:\n",
    "                R[obs_pos:obs_pos+Nq, obs_pos:obs_pos+Nq] = np.eye(Nq) * 1e-12\n",
    "                obs_pos += Nq\n",
    "                \n",
    "                # VAR-to-latent constraint noise (extremely low)\n",
    "                R[obs_pos:obs_pos+Nq, obs_pos:obs_pos+Nq] = np.eye(Nq) * 1e-14\n",
    "                obs_pos += Nq\n",
    "            \n",
    "            # Add VAR-latent alignment constraints outside month/quarter end if included\n",
    "            if not monthly_constraints_added and t % 5 == 0:\n",
    "                R[obs_pos:obs_pos+Nm, obs_pos:obs_pos+Nm] = np.eye(Nm) * 1e-12\n",
    "                obs_pos += Nm\n",
    "                \n",
    "            if not quarterly_constraints_added and t % 10 == 0:\n",
    "                R[obs_pos:obs_pos+Nq, obs_pos:obs_pos+Nq] = np.eye(Nq) * 1e-12\n",
    "                obs_pos += Nq\n",
    "            \n",
    "            # UPDATE STEP WITH NUMERICAL STABILITY\n",
    "            # ------------------------------\n",
    "            y_hat = H @ a_pred\n",
    "            nu = y - y_hat  # Innovation\n",
    "            \n",
    "            # Innovation covariance - with careful regularization\n",
    "            S = H @ P_pred @ H.T + R\n",
    "            S = 0.5 * (S + S.T)  # Ensure perfect symmetry\n",
    "            \n",
    "            # Add regularization more safely\n",
    "            S_reg = S.copy()\n",
    "            try:\n",
    "                # Use eigvalsh for symmetric matrices which returns real eigenvalues\n",
    "                eig_vals = np.linalg.eigvalsh(S)\n",
    "                min_eig = np.min(eig_vals)\n",
    "                if min_eig < 1e-10:\n",
    "                    S_reg += np.eye(S.shape[0]) * (1e-10 - min_eig)\n",
    "            except:\n",
    "                # Fallback to simple regularization if eigvalsh fails\n",
    "                S_reg += np.eye(S.shape[0]) * 1e-8\n",
    "                if j == 0 and t < 10:\n",
    "                    print(f\"Warning: Using diagonal regularization for S at t={t}\")\n",
    "            \n",
    "            try:\n",
    "                # Kalman gain\n",
    "                K = P_pred @ H.T @ invert_matrix(S_reg)\n",
    "                \n",
    "                # Update state and covariance\n",
    "                a_t = a_pred + K @ nu\n",
    "                P_t = P_pred - K @ H @ P_pred\n",
    "                \n",
    "                # Force symmetry more carefully\n",
    "                P_t = 0.5 * (P_t + P_t.T)  # Ensure perfect symmetry\n",
    "                \n",
    "                # Force positive definiteness more robustly\n",
    "                try:\n",
    "                    # Use eigvalsh for symmetric matrices\n",
    "                    eig_vals = np.linalg.eigvalsh(P_t)\n",
    "                    min_eig = np.min(eig_vals)\n",
    "                    if min_eig < 1e-8:\n",
    "                        P_t += np.eye(P_t.shape[0]) * (1e-8 - min_eig)\n",
    "                except:\n",
    "                    # If eigvalsh fails, use a more brute-force approach\n",
    "                    P_t += np.eye(P_t.shape[0]) * 1e-6\n",
    "                    if j == 0 and t < 10:\n",
    "                        print(f\"Warning: Using diagonal regularization for P_t at t={t}\")\n",
    "                \n",
    "                # ENHANCED MEASUREMENT EQUATION ENFORCEMENT\n",
    "                # ------------------------------------------------\n",
    "                \n",
    "                # Month-end constraint enforcement using the measurement equation\n",
    "                if is_month_end and m_idx >= 0 and m_idx < YM.shape[0]:\n",
    "                    for m in range(Nm):\n",
    "                        # Get observed monthly value\n",
    "                        m_obs = YM[m_idx, m]\n",
    "                        var_block_idx = Nw + m\n",
    "                        \n",
    "                        # 1. First let's set the VAR block variable to match observation with high precision\n",
    "                        # This is done through a \"phantom\" observation using the Kalman update\n",
    "                        H_phantom = np.zeros((1, nstate))\n",
    "                        H_phantom[0, var_block_idx] = 1.0\n",
    "                        y_phantom = np.array([m_obs])\n",
    "                        R_phantom = np.array([[1e-12]])  # Very low measurement noise\n",
    "                        \n",
    "                        # Kalman gain for this phantom observation\n",
    "                        S_phantom = H_phantom @ P_t @ H_phantom.T + R_phantom\n",
    "                        K_phantom = P_t @ H_phantom.T @ np.linalg.inv(S_phantom)\n",
    "                        \n",
    "                        # Apply update\n",
    "                        a_t = a_t + K_phantom @ (y_phantom - H_phantom @ a_t)\n",
    "                        P_t = P_t - K_phantom @ H_phantom @ P_t\n",
    "                        \n",
    "                        # 2. Now enforce the temporal aggregation constraint with high precision\n",
    "                        # Build measurement matrix for aggregation\n",
    "                        H_agg = np.zeros((1, nstate))\n",
    "                        for w in range(rmw):\n",
    "                            state_idx = monthly_start + w*Nm + m\n",
    "                            if self.temp_agg == 'mean':\n",
    "                                H_agg[0, state_idx] = 1.0/rmw\n",
    "                            else:  # 'sum'\n",
    "                                H_agg[0, state_idx] = 1.0\n",
    "                        \n",
    "                        # Use phantom observation for aggregation\n",
    "                        y_agg = np.array([m_obs])\n",
    "                        R_agg = np.array([[1e-12]])  # Very low measurement noise\n",
    "                        \n",
    "                        # Kalman gain for aggregation\n",
    "                        S_agg = H_agg @ P_t @ H_agg.T + R_agg\n",
    "                        K_agg = P_t @ H_agg.T @ np.linalg.inv(S_agg)\n",
    "                        \n",
    "                        # Apply update\n",
    "                        a_t = a_t + K_agg @ (y_agg - H_agg @ a_t)\n",
    "                        P_t = P_t - K_agg @ H_agg @ P_t\n",
    "                        \n",
    "                        # 3. Enforce first-week alignment with VAR block\n",
    "                        H_align = np.zeros((1, nstate))\n",
    "                        H_align[0, var_block_idx] = 1.0  # VAR block\n",
    "                        H_align[0, monthly_start + m] = -1.0  # First week\n",
    "                        \n",
    "                        y_align = np.array([0.0])  # Zero difference\n",
    "                        R_align = np.array([[1e-12]])\n",
    "                        \n",
    "                        # Kalman gain for alignment\n",
    "                        S_align = H_align @ P_t @ H_align.T + R_align\n",
    "                        K_align = P_t @ H_align.T @ np.linalg.inv(S_align)\n",
    "                        \n",
    "                        # Apply update\n",
    "                        a_t = a_t + K_align @ (y_align - H_align @ a_t)\n",
    "                        P_t = P_t - K_align @ H_align @ P_t\n",
    "                        \n",
    "                        # 4. Apply value clipping afterward to prevent extreme values\n",
    "                        threshold = 3.0\n",
    "                        for w in range(rmw):\n",
    "                            state_idx = monthly_start + w*Nm + m\n",
    "                            if np.isnan(a_t[state_idx]) or np.isinf(a_t[state_idx]) or abs(a_t[state_idx]) > threshold:\n",
    "                                # Use a more conservative value but preserve some variability\n",
    "                                pattern_factor = 0.95 + 0.1 * (w / (rmw-1))\n",
    "                                a_t[state_idx] = np.sign(a_t[state_idx]) * min(threshold, abs(m_obs) * pattern_factor)\n",
    "                        \n",
    "                        # 5. Verify the constraint is reasonably enforced (for debugging)\n",
    "                        if self.temp_agg == 'mean':\n",
    "                            agg_value = np.mean([a_t[monthly_start + w*Nm + m] for w in range(rmw)])\n",
    "                        else:\n",
    "                            agg_value = np.sum([a_t[monthly_start + w*Nm + m] for w in range(rmw)])\n",
    "                        \n",
    "                        # Print verification for first few draws\n",
    "                        if j == 0 and t < 10:\n",
    "                            error = abs(agg_value - m_obs)\n",
    "                            print(f\"  Month {m_idx+1}, Var {m+1}: Target={m_obs:.8f}, Achieved={agg_value:.8f}, Error={error:.10f}\")\n",
    "                \n",
    "                # Quarter-end constraint enforcement using measurement equation - similar approach\n",
    "                if is_quarter_end and q_idx >= 0 and q_idx < YQ.shape[0]:\n",
    "                    for q in range(Nq):\n",
    "                        # Get observed quarterly value\n",
    "                        q_obs = YQ[q_idx, q]\n",
    "                        var_block_idx = Nw + Nm + q\n",
    "                        \n",
    "                        # 1. Set VAR block variable with high precision\n",
    "                        H_phantom = np.zeros((1, nstate))\n",
    "                        H_phantom[0, var_block_idx] = 1.0\n",
    "                        y_phantom = np.array([q_obs])\n",
    "                        R_phantom = np.array([[1e-12]])\n",
    "                        \n",
    "                        # Kalman gain for phantom observation\n",
    "                        S_phantom = H_phantom @ P_t @ H_phantom.T + R_phantom\n",
    "                        K_phantom = P_t @ H_phantom.T @ np.linalg.inv(S_phantom)\n",
    "                        \n",
    "                        # Apply update\n",
    "                        a_t = a_t + K_phantom @ (y_phantom - H_phantom @ a_t)\n",
    "                        P_t = P_t - K_phantom @ H_phantom @ P_t\n",
    "                        \n",
    "                        # 2. Enforce temporal aggregation constraint\n",
    "                        H_agg = np.zeros((1, nstate))\n",
    "                        for w in range(rqw):\n",
    "                            state_idx = quarterly_start + w*Nq + q\n",
    "                            if self.temp_agg == 'mean':\n",
    "                                H_agg[0, state_idx] = 1.0/rqw\n",
    "                            else:  # 'sum'\n",
    "                                H_agg[0, state_idx] = 1.0\n",
    "                        \n",
    "                        # Use phantom observation\n",
    "                        y_agg = np.array([q_obs])\n",
    "                        R_agg = np.array([[1e-12]])\n",
    "                        \n",
    "                        # Kalman gain for aggregation\n",
    "                        S_agg = H_agg @ P_t @ H_agg.T + R_agg\n",
    "                        K_agg = P_t @ H_agg.T @ np.linalg.inv(S_agg)\n",
    "                        \n",
    "                        # Apply update\n",
    "                        a_t = a_t + K_agg @ (y_agg - H_agg @ a_t)\n",
    "                        P_t = P_t - K_agg @ H_agg @ P_t\n",
    "                        \n",
    "                        # 3. Enforce first-week alignment with VAR block\n",
    "                        H_align = np.zeros((1, nstate))\n",
    "                        H_align[0, var_block_idx] = 1.0  # VAR block\n",
    "                        H_align[0, quarterly_start + q] = -1.0  # First week\n",
    "                        \n",
    "                        y_align = np.array([0.0])  # Zero difference\n",
    "                        R_align = np.array([[1e-12]])\n",
    "                        \n",
    "                        # Kalman gain for alignment\n",
    "                        S_align = H_align @ P_t @ H_align.T + R_align\n",
    "                        K_align = P_t @ H_align.T @ np.linalg.inv(S_align)\n",
    "                        \n",
    "                        # Apply update\n",
    "                        a_t = a_t + K_align @ (y_align - H_align @ a_t)\n",
    "                        P_t = P_t - K_align @ H_align @ P_t\n",
    "                        \n",
    "                        # 4. Apply value clipping to prevent extremes\n",
    "                        threshold = 3.0\n",
    "                        for w in range(rqw):\n",
    "                            state_idx = quarterly_start + w*Nq + q\n",
    "                            if np.isnan(a_t[state_idx]) or np.isinf(a_t[state_idx]) or abs(a_t[state_idx]) > threshold:\n",
    "                                # Use conservative value but preserve some variability\n",
    "                                pattern_factor = 0.95 + 0.1 * np.sin(np.pi * w / rqw)\n",
    "                                a_t[state_idx] = np.sign(a_t[state_idx]) * min(threshold, abs(q_obs) * pattern_factor)\n",
    "                        \n",
    "                        # 5. Verify constraint (for debugging)\n",
    "                        if self.temp_agg == 'mean':\n",
    "                            agg_value = np.mean([a_t[quarterly_start + w*Nq + q] for w in range(rqw)])\n",
    "                        else:\n",
    "                            agg_value = np.sum([a_t[quarterly_start + w*Nq + q] for w in range(rqw)])\n",
    "                        \n",
    "                        # Print verification for first few draws\n",
    "                        if j == 0 and t < 10:\n",
    "                            error = abs(agg_value - q_obs)\n",
    "                            print(f\"  Quarter {q_idx+1}, Var {q+1}: Target={q_obs:.8f}, Achieved={agg_value:.8f}, Error={error:.10f}\")\n",
    "                \n",
    "                # ENHANCED VALUE CLAMPING\n",
    "                # Apply global state value clipping\n",
    "                for i in range(nstate):\n",
    "                    # More aggressive clipping for latent states\n",
    "                    if i >= monthly_start:\n",
    "                        if np.isnan(a_t[i]) or np.isinf(a_t[i]):\n",
    "                            a_t[i] = 0.0  # Reset to zero if NaN or Inf\n",
    "                        elif abs(a_t[i]) > 3.0:  # Stricter threshold\n",
    "                            a_t[i] = np.sign(a_t[i]) * 3.0  # Clip to ±3.0\n",
    "                            \n",
    "                    # Standard clipping for VAR block\n",
    "                    else:\n",
    "                        if np.isnan(a_t[i]) or np.isinf(a_t[i]):\n",
    "                            a_t[i] = 0.0\n",
    "                        elif abs(a_t[i]) > 5.0:\n",
    "                            a_t[i] = np.sign(a_t[i]) * 5.0\n",
    "                \n",
    "                # ADDITIONAL GLOBAL STATE MONITORING\n",
    "                # Periodically scan and reset problematic states\n",
    "                if t % 10 == 0:\n",
    "                    # Check for any remaining extreme values or instabilities\n",
    "                    for i in range(nstate):\n",
    "                        if abs(a_t[i]) > 2.0 and i >= monthly_start:\n",
    "                            # For latent states, set to conservative default if still extreme\n",
    "                            if i < quarterly_start:  # Monthly latent\n",
    "                                m = (i - monthly_start) % Nm\n",
    "                                w = (i - monthly_start) // Nm\n",
    "                                if m_idx >= 0 and m_idx < YM.shape[0]:\n",
    "                                    # Set to monthly value with small deviation\n",
    "                                    m_val = YM[m_idx, m]\n",
    "                                    a_t[i] = m_val * (0.95 + 0.1 * w / rmw)\n",
    "                                else:\n",
    "                                    a_t[i] = 0.5  # Conservative default\n",
    "                            else:  # Quarterly latent\n",
    "                                q = (i - quarterly_start) % Nq\n",
    "                                w = (i - quarterly_start) // Nq\n",
    "                                if q_idx >= 0 and q_idx < YQ.shape[0]:\n",
    "                                    # Set to quarterly value with small deviation\n",
    "                                    q_val = YQ[q_idx, q]\n",
    "                                    a_t[i] = q_val * (0.95 + 0.1 * w / rqw)\n",
    "                                else:\n",
    "                                    a_t[i] = 0.5\n",
    "                                \n",
    "                            # Reduce uncertainty for reset states\n",
    "                            P_t[i, i] = 1e-6\n",
    "                \n",
    "            except np.linalg.LinAlgError as e:\n",
    "                if j == 0:\n",
    "                    print(f\"Warning: Matrix inversion failed at t={t}. Using prediction only. Error: {str(e)}\")\n",
    "                a_t = a_pred\n",
    "                P_t = P_pred\n",
    "                \n",
    "                # Apply value clamping even when falling back to prediction\n",
    "                threshold = 5.0\n",
    "                for i in range(len(a_t)):\n",
    "                    if np.isnan(a_t[i]) or np.isinf(a_t[i]) or abs(a_t[i]) > threshold:\n",
    "                        a_t[i] = threshold * np.sign(a_t[i]) if a_t[i] != 0 else 0.001\n",
    "            \n",
    "            # Store filtered state and covariance\n",
    "            a_filtered[t] = a_t\n",
    "            P_filtered[t] = P_t\n",
    "        \n",
    "        # KALMAN SMOOTHER\n",
    "        # -------------\n",
    "        \n",
    "        # Initialize smoother with last filtered state\n",
    "        a_smooth = np.zeros((nobs, nstate))\n",
    "        P_smooth = np.zeros((nobs, nstate, nstate))\n",
    "        \n",
    "        # Last state is the same for filtered and smoothed\n",
    "        a_smooth[-1] = a_filtered[-1]\n",
    "        P_smooth[-1] = P_filtered[-1]\n",
    "        \n",
    "        try:\n",
    "            # Force symmetry and positive-definiteness of P_smooth[-1] before Cholesky\n",
    "            P_smooth[-1] = 0.5 * (P_smooth[-1] + P_smooth[-1].T)  # Ensure symmetry\n",
    "            \n",
    "            try:\n",
    "                # Check and fix eigenvalues\n",
    "                eig_vals = np.linalg.eigvalsh(P_smooth[-1])\n",
    "                min_eig = np.min(eig_vals)\n",
    "                if min_eig < 1e-8:\n",
    "                    P_smooth[-1] += np.eye(P_smooth[-1].shape[0]) * (1e-8 - min_eig)\n",
    "            except:\n",
    "                # Fallback to simple regularization\n",
    "                P_smooth[-1] += np.eye(P_smooth[-1].shape[0]) * 1e-6\n",
    "                if j == 0:\n",
    "                    print(\"Warning: Using diagonal regularization for P_smooth[-1]\")\n",
    "            \n",
    "            # Draw the last state\n",
    "            Pchol = cholcovOrEigendecomp(P_smooth[-1])\n",
    "            a_draw = a_smooth[-1] + Pchol @ np.random.standard_normal(nstate)\n",
    "            \n",
    "            # Apply value clamping to the draw - more aggressive for latent states\n",
    "            threshold_var = 5.0  # VAR block\n",
    "            threshold_latent = 3.0  # Latent states\n",
    "            for i in range(len(a_draw)):\n",
    "                if np.isnan(a_draw[i]) or np.isinf(a_draw[i]):\n",
    "                    a_draw[i] = a_smooth[-1][i]  # Fall back to smoothed value\n",
    "                elif i >= monthly_start:  # Latent states\n",
    "                    if abs(a_draw[i]) > threshold_latent:\n",
    "                        a_draw[i] = np.sign(a_draw[i]) * threshold_latent\n",
    "                else:  # VAR block\n",
    "                    if abs(a_draw[i]) > threshold_var:\n",
    "                        a_draw[i] = np.sign(a_draw[i]) * threshold_var\n",
    "            \n",
    "            # Final check for aggregate constraint on last state\n",
    "            last_week_idx = T0 + nobs - 1\n",
    "            last_month_idx = last_week_idx // rmw\n",
    "            last_quarter_idx = last_week_idx // rqw\n",
    "            \n",
    "            # Check if this is month-end\n",
    "            is_month_end = ((last_week_idx + 1) % rmw == 0)\n",
    "            if is_month_end and last_month_idx < YM.shape[0]:\n",
    "                for m in range(Nm):\n",
    "                    # First enforce VAR block to match observed value\n",
    "                    var_block_idx = Nw + m\n",
    "                    m_obs = YM[last_month_idx, m]\n",
    "                    a_draw[var_block_idx] = m_obs\n",
    "                    \n",
    "                    # Now enforce latent state aggregation using Kalman update approach\n",
    "                    H_agg = np.zeros((1, nstate))\n",
    "                    for w in range(rmw):\n",
    "                        state_idx = monthly_start + w*Nm + m\n",
    "                        if self.temp_agg == 'mean':\n",
    "                            H_agg[0, state_idx] = 1.0/rmw\n",
    "                        else:  # 'sum'\n",
    "                            H_agg[0, state_idx] = 1.0\n",
    "                    \n",
    "                    # Check current aggregation\n",
    "                    m_values = np.array([a_draw[monthly_start + w*Nm + m] for w in range(rmw)])\n",
    "                    if self.temp_agg == 'mean':\n",
    "                        agg_value = np.mean(m_values)\n",
    "                    else:\n",
    "                        agg_value = np.sum(m_values)\n",
    "                    \n",
    "                    # If aggregation is off by more than a small tolerance, adjust the pattern\n",
    "                    if abs(agg_value - m_obs) > 1e-6:\n",
    "                        if self.temp_agg == 'mean':\n",
    "                            # Shift pattern to match target mean while preserving shape\n",
    "                            adjustment = m_obs - agg_value\n",
    "                            for w in range(rmw):\n",
    "                                a_draw[monthly_start + w*Nm + m] += adjustment\n",
    "                        else:  # 'sum'\n",
    "                            if abs(agg_value) > 1e-10:  # Avoid division by zero\n",
    "                                # Scale pattern to match target sum while preserving shape\n",
    "                                scale = m_obs / agg_value\n",
    "                                scale = np.clip(scale, 0.5, 2.0)  # Limit scale factor\n",
    "                                for w in range(rmw):\n",
    "                                    a_draw[monthly_start + w*Nm + m] *= scale\n",
    "                            else:\n",
    "                                # If near zero, distribute evenly\n",
    "                                for w in range(rmw):\n",
    "                                    a_draw[monthly_start + w*Nm + m] = m_obs / rmw\n",
    "            \n",
    "            # Check if this is quarter-end\n",
    "            is_quarter_end = ((last_week_idx + 1) % rqw == 0)\n",
    "            if is_quarter_end and last_quarter_idx < YQ.shape[0]:\n",
    "                for q in range(Nq):\n",
    "                    # First enforce VAR block to match observed value\n",
    "                    var_block_idx = Nw + Nm + q\n",
    "                    q_obs = YQ[last_quarter_idx, q]\n",
    "                    a_draw[var_block_idx] = q_obs\n",
    "                    \n",
    "                    # Now enforce latent state aggregation using Kalman update approach\n",
    "                    H_agg = np.zeros((1, nstate))\n",
    "                    for w in range(rqw):\n",
    "                        state_idx = quarterly_start + w*Nq + q\n",
    "                        if self.temp_agg == 'mean':\n",
    "                            H_agg[0, state_idx] = 1.0/rqw\n",
    "                        else:  # 'sum'\n",
    "                            H_agg[0, state_idx] = 1.0\n",
    "                    \n",
    "                    # Check current aggregation\n",
    "                    q_values = np.array([a_draw[quarterly_start + w*Nq + q] for w in range(rqw)])\n",
    "                    if self.temp_agg == 'mean':\n",
    "                        agg_value = np.mean(q_values)\n",
    "                    else:\n",
    "                        agg_value = np.sum(q_values)\n",
    "                    \n",
    "                    # If aggregation is off by more than a small tolerance, adjust the pattern\n",
    "                    if abs(agg_value - q_obs) > 1e-6:\n",
    "                        if self.temp_agg == 'mean':\n",
    "                            # Shift pattern to match target mean while preserving shape\n",
    "                            adjustment = q_obs - agg_value\n",
    "                            for w in range(rqw):\n",
    "                                a_draw[quarterly_start + w*Nq + q] += adjustment\n",
    "                        else:  # 'sum'\n",
    "                            if abs(agg_value) > 1e-10:  # Avoid division by zero\n",
    "                                # Scale pattern to match target sum while preserving shape\n",
    "                                scale = q_obs / agg_value\n",
    "                                scale = np.clip(scale, 0.75, 1.5)  # Tighter limits for quarterly\n",
    "                                for w in range(rqw):\n",
    "                                    a_draw[quarterly_start + w*Nq + q] *= scale\n",
    "                            else:\n",
    "                                # If near zero, distribute evenly\n",
    "                                for w in range(rqw):\n",
    "                                    a_draw[quarterly_start + w*Nq + q] = q_obs / rqw\n",
    "            \n",
    "            # Store the draw\n",
    "            a_draws[j, -1] = a_draw\n",
    "            \n",
    "            # Backward recursion\n",
    "            for t in range(nobs-2, -1, -1):\n",
    "                # Get filtered state and covariance\n",
    "                a_filt = a_filtered[t]\n",
    "                P_filt = P_filtered[t]\n",
    "                \n",
    "                # Predict one step ahead\n",
    "                a_pred = F @ a_filt + c.flatten()\n",
    "                P_pred = F @ P_filt @ F.T + Q\n",
    "                P_pred = 0.5 * (P_pred + P_pred.T)  # Ensure symmetry\n",
    "                \n",
    "                try:\n",
    "                    # Add regularization to P_pred before inversion if needed\n",
    "                    P_pred_reg = P_pred.copy()\n",
    "                    try:\n",
    "                        eig_vals = np.linalg.eigvalsh(P_pred)\n",
    "                        min_eig = np.min(eig_vals)\n",
    "                        if min_eig < 1e-8:\n",
    "                            P_pred_reg += np.eye(P_pred.shape[0]) * (1e-8 - min_eig)\n",
    "                    except:\n",
    "                        # Fallback to simple regularization\n",
    "                        P_pred_reg += np.eye(P_pred.shape[0]) * 1e-6\n",
    "                    \n",
    "                    # Smoothing gain\n",
    "                    J_t = P_filt @ F.T @ invert_matrix(P_pred_reg)\n",
    "                    \n",
    "                    # Smoothed mean and covariance\n",
    "                    a_smooth_t = a_filt + J_t @ (a_draw - a_pred)\n",
    "                    P_smooth_t = P_filt - J_t @ (P_pred - P_smooth[t+1]) @ J_t.T\n",
    "                    P_smooth_t = 0.5 * (P_smooth_t + P_smooth_t.T)  # Ensure symmetry\n",
    "                    \n",
    "                    # Force positive definiteness\n",
    "                    try:\n",
    "                        eig_vals = np.linalg.eigvalsh(P_smooth_t)\n",
    "                        min_eig = np.min(eig_vals)\n",
    "                        if min_eig < 1e-8:\n",
    "                            P_smooth_t += np.eye(P_smooth_t.shape[0]) * (1e-8 - min_eig)\n",
    "                    except:\n",
    "                        # Fallback\n",
    "                        P_smooth_t += np.eye(P_smooth_t.shape[0]) * 1e-6\n",
    "                    \n",
    "                    # Store smoothed state and covariance\n",
    "                    a_smooth[t] = a_smooth_t\n",
    "                    P_smooth[t] = P_smooth_t\n",
    "                    \n",
    "                    # Draw state\n",
    "                    Pchol = cholcovOrEigendecomp(P_smooth_t)\n",
    "                    a_draw = a_smooth_t + Pchol @ np.random.standard_normal(nstate)\n",
    "                    \n",
    "                    # Apply value clamping to the draw - more aggressive for latent states\n",
    "                    threshold_var = 5.0  # VAR block\n",
    "                    threshold_latent = 3.0  # Latent states\n",
    "                    for i in range(len(a_draw)):\n",
    "                        if np.isnan(a_draw[i]) or np.isinf(a_draw[i]):\n",
    "                            a_draw[i] = a_smooth_t[i]  # Fall back to smoothed value\n",
    "                        elif i >= monthly_start:  # Latent states\n",
    "                            if abs(a_draw[i]) > threshold_latent:\n",
    "                                a_draw[i] = np.sign(a_draw[i]) * threshold_latent\n",
    "                        else:  # VAR block\n",
    "                            if abs(a_draw[i]) > threshold_var:\n",
    "                                a_draw[i] = np.sign(a_draw[i]) * threshold_var\n",
    "                    \n",
    "                    # Check and enforce constraints for this period\n",
    "                    w_idx = T0 + t\n",
    "                    m_idx = w_idx // rmw\n",
    "                    q_idx = w_idx // rqw\n",
    "                    \n",
    "                    # Check if this is month-end\n",
    "                    is_month_end = ((w_idx + 1) % rmw == 0)\n",
    "                    if is_month_end and m_idx < YM.shape[0]:\n",
    "                        for m in range(Nm):\n",
    "                            # First enforce VAR block to match observed value\n",
    "                            var_block_idx = Nw + m\n",
    "                            m_obs = YM[m_idx, m]\n",
    "                            a_draw[var_block_idx] = m_obs\n",
    "                            \n",
    "                            # Now enforce latent state aggregation using Kalman update approach\n",
    "                            # Check current aggregation\n",
    "                            m_values = np.array([a_draw[monthly_start + w*Nm + m] for w in range(rmw)])\n",
    "                            if self.temp_agg == 'mean':\n",
    "                                agg_value = np.mean(m_values)\n",
    "                            else:\n",
    "                                agg_value = np.sum(m_values)\n",
    "                            \n",
    "                            # If aggregation is off by more than a small tolerance, adjust the pattern\n",
    "                            if abs(agg_value - m_obs) > 1e-6:\n",
    "                                if self.temp_agg == 'mean':\n",
    "                                    # Shift pattern to match target mean while preserving shape\n",
    "                                    adjustment = m_obs - agg_value\n",
    "                                    for w in range(rmw):\n",
    "                                        a_draw[monthly_start + w*Nm + m] += adjustment\n",
    "                                else:  # 'sum'\n",
    "                                    if abs(agg_value) > 1e-10:  # Avoid division by zero\n",
    "                                        # Scale pattern to match target sum while preserving shape\n",
    "                                        scale = m_obs / agg_value\n",
    "                                        scale = np.clip(scale, 0.5, 2.0)  # Limit scale factor\n",
    "                                        for w in range(rmw):\n",
    "                                            a_draw[monthly_start + w*Nm + m] *= scale\n",
    "                                    else:\n",
    "                                        # If near zero, distribute evenly\n",
    "                                        for w in range(rmw):\n",
    "                                            a_draw[monthly_start + w*Nm + m] = m_obs / rmw\n",
    "                    \n",
    "                    # Check if this is quarter-end\n",
    "                    is_quarter_end = ((w_idx + 1) % rqw == 0)\n",
    "                    if is_quarter_end and q_idx < YQ.shape[0]:\n",
    "                        for q in range(Nq):\n",
    "                            # First enforce VAR block to match observed value\n",
    "                            var_block_idx = Nw + Nm + q\n",
    "                            q_obs = YQ[q_idx, q]\n",
    "                            a_draw[var_block_idx] = q_obs\n",
    "                            \n",
    "                            # Now enforce latent state aggregation using Kalman update approach\n",
    "                            # Check current aggregation\n",
    "                            q_values = np.array([a_draw[quarterly_start + w*Nq + q] for w in range(rqw)])\n",
    "                            if self.temp_agg == 'mean':\n",
    "                                agg_value = np.mean(q_values)\n",
    "                            else:\n",
    "                                agg_value = np.sum(q_values)\n",
    "                            \n",
    "                            # If aggregation is off by more than a small tolerance, adjust the pattern\n",
    "                            if abs(agg_value - q_obs) > 1e-6:\n",
    "                                if self.temp_agg == 'mean':\n",
    "                                    # Shift pattern to match target mean while preserving shape\n",
    "                                    adjustment = q_obs - agg_value\n",
    "                                    for w in range(rqw):\n",
    "                                        a_draw[quarterly_start + w*Nq + q] += adjustment\n",
    "                                else:  # 'sum'\n",
    "                                    if abs(agg_value) > 1e-10:  # Avoid division by zero\n",
    "                                        # Scale pattern to match target sum while preserving shape\n",
    "                                        scale = q_obs / agg_value\n",
    "                                        scale = np.clip(scale, 0.75, 1.5)  # Tighter limits for quarterly\n",
    "                                        for w in range(rqw):\n",
    "                                            a_draw[quarterly_start + w*Nq + q] *= scale\n",
    "                                    else:\n",
    "                                        # If near zero, distribute evenly\n",
    "                                        for w in range(rqw):\n",
    "                                            a_draw[quarterly_start + w*Nq + q] = q_obs / rqw\n",
    "                    \n",
    "                    # Also enforce VAR-to-latent alignment for first week of each period\n",
    "                    if (w_idx % rmw == 0) and (w_idx // rmw) < YM.shape[0]:\n",
    "                        for m in range(Nm):\n",
    "                            # Force first week to match VAR block\n",
    "                            a_draw[monthly_start + m] = a_draw[Nw + m]\n",
    "                    \n",
    "                    if (w_idx % rqw == 0) and (w_idx // rqw) < YQ.shape[0]:\n",
    "                        for q in range(Nq):\n",
    "                            # Force first week to match VAR block\n",
    "                            a_draw[quarterly_start + q] = a_draw[Nw + Nm + q]\n",
    "                    \n",
    "                    # Store the draw\n",
    "                    a_draws[j, t] = a_draw\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    # Fallback for smoother error\n",
    "                    if j == 0:\n",
    "                        print(f\"Smoother error at t={t}: {str(e)}\")\n",
    "                    a_smooth[t] = a_filtered[t]\n",
    "                    P_smooth[t] = P_filtered[t]\n",
    "                    \n",
    "                    # Use filtered state with small noise but apply value clamping\n",
    "                    a_draws[j, t] = a_filtered[t] + np.random.standard_normal(nstate) * 1e-4\n",
    "                    \n",
    "                    # Apply value clamping\n",
    "                    threshold = 5.0\n",
    "                    for i in range(len(a_draws[j, t])):\n",
    "                        if np.isnan(a_draws[j, t, i]) or np.isinf(a_draws[j, t, i]) or abs(a_draws[j, t, i]) > threshold:\n",
    "                            a_draws[j, t, i] = threshold * np.sign(a_draws[j, t, i]) if a_draws[j, t, i] != 0 else 0.001\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Fallback for smoother initialization error\n",
    "            if j == 0:\n",
    "                print(f\"Smoother initialization error: {str(e)}\")\n",
    "            \n",
    "            # Copy filtered states but apply value clamping\n",
    "            for t in range(nobs):\n",
    "                a_draws[j, t] = a_filtered[t]\n",
    "                # Apply value clamping\n",
    "                threshold = 5.0\n",
    "                for i in range(len(a_draws[j, t])):\n",
    "                    if np.isnan(a_draws[j, t, i]) or np.isinf(a_draws[j, t, i]) or abs(a_draws[j, t, i]) > threshold:\n",
    "                        a_draws[j, t, i] = threshold * np.sign(a_draws[j, t, i]) if a_draws[j, t, i] != 0 else 0.001\n",
    "            \n",
    "        # FINAL VERIFICATION FOR THIS DRAW\n",
    "        # ------------------------------\n",
    "        \n",
    "        # Verify key constraints for debugging\n",
    "        if j == 0 or j == self.nsim - 1:\n",
    "            constraint_errors = 0\n",
    "            \n",
    "            # Check all month-ends\n",
    "            for t in range(nobs):\n",
    "                w_idx = T0 + t\n",
    "                # Check if this is month-end\n",
    "                if (w_idx + 1) % rmw == 0:\n",
    "                    m_idx = w_idx // rmw\n",
    "                    if m_idx < YM.shape[0]:\n",
    "                        for m in range(Nm):\n",
    "                            # Get latent states\n",
    "                            m_values = np.zeros(rmw)\n",
    "                            for w in range(rmw):\n",
    "                                m_values[w] = a_draws[j, t, monthly_start + w*Nm + m]\n",
    "                            \n",
    "                            # Check aggregation\n",
    "                            if self.temp_agg == 'mean':\n",
    "                                agg_value = np.mean(m_values)\n",
    "                            else:\n",
    "                                agg_value = np.sum(m_values)\n",
    "                            \n",
    "                            error = abs(agg_value - YM[m_idx, m])\n",
    "                            if error > 1e-6:\n",
    "                                constraint_errors += 1\n",
    "                                if constraint_errors <= 5:  # Limit output\n",
    "                                    print(f\"Draw {j}, Month {m_idx+1}, Var {m+1}: Agg={agg_value:.8f}, \"\n",
    "                                          f\"Target={YM[m_idx, m]:.8f}, Error={error:.8f}\")\n",
    "            \n",
    "            # Check all quarter-ends\n",
    "            for t in range(nobs):\n",
    "                w_idx = T0 + t\n",
    "                # Check if this is quarter-end\n",
    "                if (w_idx + 1) % rqw == 0:\n",
    "                    q_idx = w_idx // rqw\n",
    "                    if q_idx < YQ.shape[0]:\n",
    "                        for q in range(Nq):\n",
    "                            # Get latent states\n",
    "                            q_values = np.zeros(rqw)\n",
    "                            for w in range(rqw):\n",
    "                                q_values[w] = a_draws[j, t, quarterly_start + w*Nq + q]\n",
    "                            \n",
    "                            # Check aggregation\n",
    "                            if self.temp_agg == 'mean':\n",
    "                                agg_value = np.mean(q_values)\n",
    "                            else:\n",
    "                                agg_value = np.sum(q_values)\n",
    "                            \n",
    "                            error = abs(agg_value - YQ[q_idx, q])\n",
    "                            if error > 1e-6:\n",
    "                                constraint_errors += 1\n",
    "                                if constraint_errors <= 5:  # Limit output\n",
    "                                    print(f\"Draw {j}, Quarter {q_idx+1}, Var {q+1}: Agg={agg_value:.8f}, \"\n",
    "                                          f\"Target={YQ[q_idx, q]:.8f}, Error={error:.8f}\")\n",
    "            \n",
    "            if constraint_errors > 0:\n",
    "                print(f\"Draw {j}: Found {constraint_errors} constraint violations\")\n",
    "            else:\n",
    "                print(f\"Draw {j}: All aggregation constraints satisfied\")\n",
    "        \n",
    "        # CALCULATE VAR POSTERIOR USING ALL VARIABLES\n",
    "        # ---------------------------------------\n",
    "        \n",
    "        # Create a combined matrix of all variables for VAR estimation\n",
    "        combined_smooth = np.zeros((nobs, Ntotal))\n",
    "        \n",
    "        # Weekly variables (direct)\n",
    "        combined_smooth[:, :Nw] = a_draws[j, :, :Nw]\n",
    "        \n",
    "        # Monthly variables (from state vector)\n",
    "        combined_smooth[:, Nw:Nw+Nm] = a_draws[j, :, Nw:Nw+Nm]\n",
    "        \n",
    "        # Quarterly variables (from state vector)\n",
    "        combined_smooth[:, Nw+Nm:Ntotal] = a_draws[j, :, Nw+Nm:Ntotal]\n",
    "        \n",
    "        # Use the combined matrix for VAR estimation\n",
    "        YY = combined_smooth\n",
    "        \n",
    "        # Prepare lagged data for the VAR\n",
    "        Z = np.zeros((nobs, Ntotal * p))\n",
    "        for i in range(nobs):\n",
    "            for lag in range(p):\n",
    "                if i - lag >= 0:\n",
    "                    Z[i, lag*Ntotal:(lag+1)*Ntotal] = YY[i-lag]\n",
    "        \n",
    "        # Compute actual observations for Minnesota prior\n",
    "        nobs_ = YY.shape[0] - p  # Adjusted for lags\n",
    "        spec = np.hstack((p, p, self.nex, Ntotal, nobs_))  # Now using all variables (Ntotal)\n",
    "        \n",
    "        # Calculate dummy observations for the full VAR\n",
    "        YYact, YYdum, XXact, XXdum = calc_yyact(self.hyp, YY, spec)\n",
    "        \n",
    "        # Store simulation results for all variables\n",
    "        if (j % self.thining == 0):\n",
    "            j_temp = int(j/self.thining)\n",
    "            if j == 0:\n",
    "                # Initialize storage for all variables\n",
    "                YYactsim_list = [np.zeros((math.ceil((self.nsim)/self.thining), rmw, Ntotal))]\n",
    "                XXactsim_list = [np.zeros((math.ceil((self.nsim)/self.thining), rmw, Ntotal*p+1))]  # For all variables\n",
    "            \n",
    "            # Store the combined data\n",
    "            YYactsim_list[0][j_temp, :, :] = combined_smooth[-rmw:, :]\n",
    "            \n",
    "            # Create lagged data matrix for all variables\n",
    "            X_combined = np.zeros((rmw, Ntotal*p+1))\n",
    "            for i in range(rmw):\n",
    "                for lag in range(p):\n",
    "                    t_idx = nobs - rmw + i - lag\n",
    "                    if t_idx >= 0:\n",
    "                        X_combined[i, lag*Ntotal:(lag+1)*Ntotal] = combined_smooth[t_idx, :]\n",
    "            X_combined[:, -1] = 1.0  # Add constant\n",
    "            \n",
    "            XXactsim_list[0][j_temp, :, :] = X_combined\n",
    "        \n",
    "        # VAR POSTERIOR SAMPLING\n",
    "        # -------------------\n",
    "        \n",
    "        try:\n",
    "            # Standard VAR posterior calculations\n",
    "            Tdummy, n = YYdum.shape\n",
    "            n = int(n)\n",
    "            Tdummy = int(Tdummy)\n",
    "            Tobs, n = YYact.shape\n",
    "            X = np.vstack((XXact, XXdum))\n",
    "            Y = np.vstack((YYact, YYdum))\n",
    "            T = Tobs + Tdummy\n",
    "            \n",
    "            # Compute posterior parameters\n",
    "            vl, d, vr = np.linalg.svd(X, full_matrices=False)\n",
    "            vr = vr.T\n",
    "            di = 1/d\n",
    "            B = vl.T @ Y\n",
    "            xxi = (vr * np.tile(di.T, (Ntotal*p+1, 1)))\n",
    "            inv_x = xxi @ xxi.T\n",
    "            Phi_tilde = xxi @ B\n",
    "            \n",
    "            Sigma = (Y - X @ Phi_tilde).T @ (Y - X @ Phi_tilde)\n",
    "            \n",
    "            # Ensure Sigma is symmetric positive definite before inverse Wishart draw\n",
    "            Sigma = 0.5 * (Sigma + Sigma.T)\n",
    "            \n",
    "            try:\n",
    "                # Check and fix eigenvalues if needed\n",
    "                eig_vals = np.linalg.eigvalsh(Sigma)\n",
    "                min_eig = np.min(eig_vals)\n",
    "                if min_eig < 1e-8:\n",
    "                    Sigma += np.eye(Sigma.shape[0]) * (1e-8 - min_eig)\n",
    "            except:\n",
    "                # Fallback to simple regularization\n",
    "                Sigma += np.eye(Sigma.shape[0]) * 1e-6\n",
    "                if j == 0:\n",
    "                    print(\"Warning: Using diagonal regularization for Sigma\")\n",
    "            \n",
    "            # Draw from inverse Wishart for covariance matrix\n",
    "            sigma_w = invwishart.rvs(scale=Sigma, df=T-Ntotal*p-1)\n",
    "            \n",
    "            # Draw VAR coefficients and check stability\n",
    "            attempts = 0\n",
    "            while attempts < 1000:\n",
    "                try:\n",
    "                    # Compute Cholesky safely\n",
    "                    kron_matrix = np.kron(sigma_w, inv_x)\n",
    "                    kron_matrix = 0.5 * (kron_matrix + kron_matrix.T)  # Ensure symmetry\n",
    "                    \n",
    "                    try:\n",
    "                        # Check eigenvalues\n",
    "                        eig_vals = np.linalg.eigvalsh(kron_matrix)\n",
    "                        min_eig = np.min(eig_vals)\n",
    "                        if min_eig < 1e-8:\n",
    "                            kron_matrix += np.eye(kron_matrix.shape[0]) * (1e-8 - min_eig)\n",
    "                    except:\n",
    "                        # Fallback\n",
    "                        kron_matrix += np.eye(kron_matrix.shape[0]) * 1e-6\n",
    "                    \n",
    "                    sigma_chol = cholcovOrEigendecomp(kron_matrix)\n",
    "                    phi_new = np.squeeze(Phi_tilde.reshape(Ntotal*(Ntotal*p+1), 1, order=\"F\")) + sigma_chol @ np.random.standard_normal(sigma_chol.shape[0])\n",
    "                    Phi_w = phi_new.reshape(Ntotal*p+1, Ntotal, order=\"F\")\n",
    "                    \n",
    "                    # NEW: Apply regularization to prevent explosive estimates\n",
    "                    # Shrink coefficients for lagged variables toward zero\n",
    "                    for lag in range(1, p+1):\n",
    "                        lag_idx_start = (lag-1) * Ntotal\n",
    "                        lag_idx_end = lag * Ntotal\n",
    "                        shrinkage_factor = 0.95 ** lag  # More shrinkage for more distant lags\n",
    "                        Phi_w[lag_idx_start:lag_idx_end, :] *= shrinkage_factor\n",
    "\n",
    "                    # Constrain diagonal elements of first lag to reasonable range\n",
    "                    for i in range(Ntotal):\n",
    "                        # First lag diagonal elements shouldn't be too extreme\n",
    "                        if abs(Phi_w[i, i]) > 0.9:\n",
    "                            Phi_w[i, i] = 0.9 * np.sign(Phi_w[i, i])\n",
    "                    \n",
    "                    if not is_explosive(Phi_w, Ntotal, p):\n",
    "                        break\n",
    "                except Exception as e:\n",
    "                    if j == 0 and attempts == 0:\n",
    "                        print(f\"VAR coefficient sampling error: {str(e)}, retrying...\")\n",
    "                \n",
    "                attempts += 1\n",
    "            \n",
    "            if attempts == 1000:\n",
    "                explosive_counter += 1\n",
    "                print(f\"Explosive VAR detected {explosive_counter} times.\")\n",
    "                continue\n",
    "            \n",
    "            # Store posterior draws\n",
    "            if (j % self.thining == 0):\n",
    "                j_temp = int(j/self.thining)\n",
    "                Sigmap[j_temp, :, :] = sigma_w\n",
    "                Phip[j_temp, :, :] = Phi_w\n",
    "                Cons[j_temp, :] = Phi_w[-1, :]\n",
    "                valid_draws.append(j_temp)\n",
    "            \n",
    "            # Update transition matrix for next iteration - now for all variables\n",
    "            F[:Ntotal, :Ntotal*p] = Phi_w[:-1, :].T  # All VAR coefficients (excluding constant)\n",
    "            c[:Ntotal] = np.atleast_2d(Phi_w[-1, :]).T  # Constants for all variables\n",
    "            \n",
    "            # Remember to keep the block structure intact for variable lags\n",
    "            for i in range(p-1):\n",
    "                F[Ntotal*(i+1):Ntotal*(i+2), Ntotal*i:Ntotal*(i+1)] = np.eye(Ntotal)\n",
    "            \n",
    "            # Monthly block shifting for latent states\n",
    "            for i in range(rmw-1):\n",
    "                src_pos = monthly_start + i*Nm\n",
    "                dest_pos = monthly_start + (i+1)*Nm\n",
    "                F[dest_pos:dest_pos+Nm, src_pos:src_pos+Nm] = np.eye(Nm)\n",
    "            \n",
    "            # Quarterly block shifting for latent states\n",
    "            for i in range(rqw-1):\n",
    "                src_pos = quarterly_start + i*Nq\n",
    "                dest_pos = quarterly_start + (i+1)*Nq\n",
    "                F[dest_pos:dest_pos+Nq, src_pos:src_pos+Nq] = np.eye(Nq)\n",
    "            \n",
    "            # Weekly influence for latent states\n",
    "            F[monthly_start:monthly_start+Nm, :Nw] = 0.1 * np.eye(Nm, Nw)\n",
    "            F[quarterly_start:quarterly_start+Nq, :Nw] = 0.05 * np.eye(Nq, Nw)\n",
    "            \n",
    "            # Update system covariance\n",
    "            Q[:Ntotal, :Ntotal] = sigma_w\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"VAR posterior sampling error: {str(e)}\")\n",
    "            continue\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.06204113,  0.0147541 , -0.01632351,  0.00509658,  0.00598903,\n",
       "        0.00840612,  0.00347586,  0.00078935,  0.05470422,  0.01375221,\n",
       "        0.025228  ,  0.02219223,  0.04823227,  0.03777257,  0.00137952,\n",
       "       -0.00305337,  0.06231899,  0.05198538, -0.13360861, -0.1378058 ,\n",
       "        0.07217633,  0.03752976, -0.10447912,  0.04598964, -0.1218911 ,\n",
       "       -0.00539067, -0.01774318,  0.11243958, -0.02407408, -0.08420003,\n",
       "       -0.10957762,  0.01094409,  0.00743447,  0.09809498, -0.07306725,\n",
       "        0.00363514, -0.05810332,  0.05794954, -0.07706872,  0.04590244,\n",
       "       -0.06554533,  0.04052807,  0.0894167 , -0.00142856, -0.06498195,\n",
       "       -0.10151555, -0.13808343,  0.01933834, -0.10416783,  0.12887093,\n",
       "        0.06001375, -0.04759814,  0.14510398,  0.08429645, -0.04219666,\n",
       "        0.02982116, -0.01102691, -0.06772813,  0.03408225,  0.17146558,\n",
       "        0.06532492, -0.05431416,  0.05453679, -0.08666135,  0.20199683,\n",
       "        0.02772652, -0.04708155,  0.06269514,  0.02306297, -0.0993386 ,\n",
       "       -0.1195505 ,  0.01247499,  0.00328659,  0.04107938, -0.05376171,\n",
       "       -0.00788551,  0.04868486, -0.01801542,  0.00705927,  0.00117946,\n",
       "        0.03942044,  0.05201016,  0.04121795,  0.01212014,  0.02177959,\n",
       "        0.0291981 , -0.02432753, -0.05960578, -0.00189456,  0.02280055,\n",
       "        0.03589036, -0.068038  ,  0.00530271, -0.01163878,  0.02617357,\n",
       "       -0.00387853,  0.00509658,  0.00598903,  0.00840612, -0.25479335,\n",
       "        0.03256911, -0.07115662,  0.14708572, -0.00280137,  0.06213284,\n",
       "        0.10160041, -0.30662609, -0.1503729 ,  0.00347586,  0.00078935,\n",
       "       -0.37015059,  0.49189391, -0.30986075,  0.0282257 ,  0.03011837,\n",
       "       -0.41796387, -0.28834014,  0.01809846, -0.22294537,  0.29595583,\n",
       "       -0.17665694, -0.19688538, -0.07798041,  0.18884415, -0.25904618,\n",
       "       -0.04208026,  0.15457866, -0.02712469, -0.14408185,  0.02087427,\n",
       "       -0.10156679, -0.13515381])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 6)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mFile \u001b[39m\u001b[32m<tokenize>:6\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mfor t in range(nobs):\u001b[39m\n    ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "if j > 0:\n",
    "            a_t = a_draws[j-1, -1]\n",
    "            P_t = P_filtered[-1]\n",
    "        \n",
    "        # Kalman filter loop through all periods\n",
    "        for t in range(nobs):\n",
    "            # Current week index\n",
    "            w_idx = T0 + t\n",
    "            \n",
    "            # PREDICTION STEP\n",
    "            # --------------\n",
    "            a_pred = F @ a_t + c.flatten()\n",
    "            P_pred = F @ P_t @ F.T + Q\n",
    "            P_pred = 0.5 * (P_pred + P_pred.T)  # Ensure perfect symmetry\n",
    "            \n",
    "            # DETERMINE AVAILABLE OBSERVATIONS\n",
    "            # -----------------------------\n",
    "            \n",
    "            # Check which observations are available at this period\n",
    "            is_quarter_end = q_obs_periods[w_idx] if w_idx < len(q_obs_periods) else False\n",
    "            is_month_end = m_obs_periods[w_idx] if w_idx < len(m_obs_periods) else False\n",
    "            \n",
    "            # Get indices for the observation vectors\n",
    "            q_idx = w_idx // rqw if is_quarter_end else -1\n",
    "            m_idx = w_idx // rmw if is_month_end else -1\n",
    "            \n",
    "            # Debug output for first few periods\n",
    "            if j == 0 and t < 5:\n",
    "                print(f\"Period {t+1}: week_idx={w_idx}, quarter_end={is_quarter_end}, month_end={is_month_end}\")\n",
    "                if is_quarter_end:\n",
    "                    print(f\"  Quarterly observation: {YQ[q_idx]}\")\n",
    "                if is_month_end:\n",
    "                    print(f\"  Monthly observation: {YM[m_idx]}\")\n",
    "            \n",
    "            # BUILD ENHANCED MEASUREMENT MATRICES AND OBSERVATION VECTOR\n",
    "            # -----------------------------------------------------\n",
    "            \n",
    "            # Start with weekly observations (always available)\n",
    "            H_matrices = [H_w]\n",
    "            y_obs = [YW[w_idx]]\n",
    "            \n",
    "            # Add monthly observations if available\n",
    "            monthly_constraints_added = False\n",
    "            if is_month_end and m_idx >= 0 and m_idx < YM.shape[0]:\n",
    "                H_matrices.append(H_m)\n",
    "                y_obs.append(YM[m_idx])\n",
    "                \n",
    "                # Always add the constraint that links VAR block to latent states\n",
    "                H_matrices.append(H_m_constraint)\n",
    "                y_obs.append(np.zeros(Nm))  # Zero difference means equality constraint\n",
    "                monthly_constraints_added = True\n",
    "            \n",
    "            # Add quarterly observations if available\n",
    "            quarterly_constraints_added = False\n",
    "            if is_quarter_end and q_idx >= 0 and q_idx < YQ.shape[0]:\n",
    "                H_matrices.append(H_q)\n",
    "                y_obs.append(YQ[q_idx])\n",
    "                \n",
    "                # Always add the constraint that links VAR block to latent states\n",
    "                H_matrices.append(H_q_constraint)\n",
    "                y_obs.append(np.zeros(Nq))  # Zero difference means equality constraint\n",
    "                quarterly_constraints_added = True\n",
    "            \n",
    "            # Also enforce VAR-latent alignment constraints at every period\n",
    "            # (not just at month/quarter end)\n",
    "            if not monthly_constraints_added and t % 5 == 0:  # Every 5 periods to avoid too much constraint\n",
    "                H_matrices.append(H_m_constraint)\n",
    "                y_obs.append(np.zeros(Nm))\n",
    "            \n",
    "            if not quarterly_constraints_added and t % 10 == 0:  # Less frequent for quarterly\n",
    "                H_matrices.append(H_q_constraint)\n",
    "                y_obs.append(np.zeros(Nq))\n",
    "            \n",
    "            # Combined measurement matrix and observation vector\n",
    "            H = np.vstack(H_matrices)\n",
    "            y = np.concatenate(y_obs)\n",
    "            \n",
    "            # DIFFERENT MEASUREMENT NOISE BY FREQUENCY - EXTREMELY PRECISE FOR CONSTRAINTS\n",
    "            # ---------------------------------------------------------------------\n",
    "            \n",
    "            # Create measurement noise matrix with precision scaled by frequency\n",
    "            R = np.zeros((len(y), len(y)))\n",
    "            \n",
    "            # Current position in the observation vector\n",
    "            obs_pos = 0\n",
    "            \n",
    "            # Weekly measurement noise (standard precision)\n",
    "            R[obs_pos:obs_pos+Nw, obs_pos:obs_pos+Nw] = np.eye(Nw) * 1e-3\n",
    "            obs_pos += Nw\n",
    "            \n",
    "            # Monthly measurement noise (extreme precision to enforce constraint)\n",
    "            if is_month_end and m_idx >= 0 and m_idx < YM.shape[0]:\n",
    "                R[obs_pos:obs_pos+Nm, obs_pos:obs_pos+Nm] = np.eye(Nm) * 1e-12\n",
    "                obs_pos += Nm\n",
    "                \n",
    "                # VAR-to-latent constraint noise (extremely low)\n",
    "                R[obs_pos:obs_pos+Nm, obs_pos:obs_pos+Nm] = np.eye(Nm) * 1e-14\n",
    "                obs_pos += Nm\n",
    "            \n",
    "            # Quarterly measurement noise (even more extreme precision)\n",
    "            if is_quarter_end and q_idx >= 0 and q_idx < YQ.shape[0]:\n",
    "                R[obs_pos:obs_pos+Nq, obs_pos:obs_pos+Nq] = np.eye(Nq) * 1e-12\n",
    "                obs_pos += Nq\n",
    "                \n",
    "                # VAR-to-latent constraint noise (extremely low)\n",
    "                R[obs_pos:obs_pos+Nq, obs_pos:obs_pos+Nq] = np.eye(Nq) * 1e-14\n",
    "                obs_pos += Nq\n",
    "            \n",
    "            # Add VAR-latent alignment constraints outside month/quarter end if included\n",
    "            if not monthly_constraints_added and t % 5 == 0:\n",
    "                R[obs_pos:obs_pos+Nm, obs_pos:obs_pos+Nm] = np.eye(Nm) * 1e-12\n",
    "                obs_pos += Nm\n",
    "                \n",
    "            if not quarterly_constraints_added and t % 10 == 0:\n",
    "                R[obs_pos:obs_pos+Nq, obs_pos:obs_pos+Nq] = np.eye(Nq) * 1e-12\n",
    "                obs_pos += Nq\n",
    "            \n",
    "            # UPDATE STEP WITH NUMERICAL STABILITY\n",
    "            # ------------------------------\n",
    "            y_hat = H @ a_pred\n",
    "            nu = y - y_hat  # Innovation\n",
    "            \n",
    "            # Innovation covariance - with careful regularization\n",
    "            S = H @ P_pred @ H.T + R\n",
    "            S = 0.5 * (S + S.T)  # Ensure perfect symmetry\n",
    "            \n",
    "            # Add regularization more safely\n",
    "            S_reg = S.copy()\n",
    "            try:\n",
    "                # Use eigvalsh for symmetric matrices which returns real eigenvalues\n",
    "                eig_vals = np.linalg.eigvalsh(S)\n",
    "                min_eig = np.min(eig_vals)\n",
    "                if min_eig < 1e-10:\n",
    "                    S_reg += np.eye(S.shape[0]) * (1e-10 - min_eig)\n",
    "            except:\n",
    "                # Fallback to simple regularization if eigvalsh fails\n",
    "                S_reg += np.eye(S.shape[0]) * 1e-8\n",
    "                if j == 0 and t < 10:\n",
    "                    print(f\"Warning: Using diagonal regularization for S at t={t}\")\n",
    "            \n",
    "            try:\n",
    "                # Kalman gain\n",
    "                K = P_pred @ H.T @ invert_matrix(S_reg)\n",
    "                \n",
    "                # Update state and covariance\n",
    "                a_t = a_pred + K @ nu\n",
    "                P_t = P_pred - K @ H @ P_pred\n",
    "                \n",
    "                # Force symmetry more carefully\n",
    "                P_t = 0.5 * (P_t + P_t.T)  # Ensure perfect symmetry\n",
    "                \n",
    "                # Force positive definiteness more robustly\n",
    "                try:\n",
    "                    # Use eigvalsh for symmetric matrices\n",
    "                    eig_vals = np.linalg.eigvalsh(P_t)\n",
    "                    min_eig = np.min(eig_vals)\n",
    "                    if min_eig < 1e-8:\n",
    "                        P_t += np.eye(P_t.shape[0]) * (1e-8 - min_eig)\n",
    "                except:\n",
    "                    # If eigvalsh fails, use a more brute-force approach\n",
    "                    P_t += np.eye(P_t.shape[0]) * 1e-6\n",
    "                    if j == 0 and t < 10:\n",
    "                        print(f\"Warning: Using diagonal regularization for P_t at t={t}\")\n",
    "                \n",
    "                # ENHANCED MEASUREMENT EQUATION ENFORCEMENT\n",
    "                # ------------------------------------------------\n",
    "                \n",
    "                # Month-end constraint enforcement using the measurement equation\n",
    "                if is_month_end and m_idx >= 0 and m_idx < YM.shape[0]:\n",
    "                    for m in range(Nm):\n",
    "                        # Get observed monthly value\n",
    "                        m_obs = YM[m_idx, m]\n",
    "                        var_block_idx = Nw + m\n",
    "                        \n",
    "                        # 1. First let's set the VAR block variable to match observation with high precision\n",
    "                        # This is done through a \"phantom\" observation using the Kalman update\n",
    "                        H_phantom = np.zeros((1, nstate))\n",
    "                        H_phantom[0, var_block_idx] = 1.0\n",
    "                        y_phantom = np.array([m_obs])\n",
    "                        R_phantom = np.array([[1e-12]])  # Very low measurement noise\n",
    "                        \n",
    "                        # Kalman gain for this phantom observation\n",
    "                        S_phantom = H_phantom @ P_t @ H_phantom.T + R_phantom\n",
    "                        K_phantom = P_t @ H_phantom.T @ np.linalg.inv(S_phantom)\n",
    "                        \n",
    "                        # Apply update\n",
    "                        a_t = a_t + K_phantom @ (y_phantom - H_phantom @ a_t)\n",
    "                        P_t = P_t - K_phantom @ H_phantom @ P_t\n",
    "                        \n",
    "                        # 2. Now enforce the temporal aggregation constraint with high precision\n",
    "                        # Build measurement matrix for aggregation\n",
    "                        H_agg = np.zeros((1, nstate))\n",
    "                        for w in range(rmw):\n",
    "                            state_idx = monthly_start + w*Nm + m\n",
    "                            if self.temp_agg == 'mean':\n",
    "                                H_agg[0, state_idx] = 1.0/rmw\n",
    "                            else:  # 'sum'\n",
    "                                H_agg[0, state_idx] = 1.0\n",
    "                        \n",
    "                        # Use phantom observation for aggregation\n",
    "                        y_agg = np.array([m_obs])\n",
    "                        R_agg = np.array([[1e-12]])  # Very low measurement noise\n",
    "                        \n",
    "                        # Kalman gain for aggregation\n",
    "                        S_agg = H_agg @ P_t @ H_agg.T + R_agg\n",
    "                        K_agg = P_t @ H_agg.T @ np.linalg.inv(S_agg)\n",
    "                        \n",
    "                        # Apply update\n",
    "                        a_t = a_t + K_agg @ (y_agg - H_agg @ a_t)\n",
    "                        P_t = P_t - K_agg @ H_agg @ P_t\n",
    "                        \n",
    "                        # 3. Enforce first-week alignment with VAR block\n",
    "                        H_align = np.zeros((1, nstate))\n",
    "                        H_align[0, var_block_idx] = 1.0  # VAR block\n",
    "                        H_align[0, monthly_start + m] = -1.0  # First week\n",
    "                        \n",
    "                        y_align = np.array([0.0])  # Zero difference\n",
    "                        R_align = np.array([[1e-12]])\n",
    "                        \n",
    "                        # Kalman gain for alignment\n",
    "                        S_align = H_align @ P_t @ H_align.T + R_align\n",
    "                        K_align = P_t @ H_align.T @ np.linalg.inv(S_align)\n",
    "                        \n",
    "                        # Apply update\n",
    "                        a_t = a_t + K_align @ (y_align - H_align @ a_t)\n",
    "                        P_t = P_t - K_align @ H_align @ P_t\n",
    "                        \n",
    "                        # 4. Apply value clipping afterward to prevent extreme values\n",
    "                        threshold = 3.0\n",
    "                        for w in range(rmw):\n",
    "                            state_idx = monthly_start + w*Nm + m\n",
    "                            if np.isnan(a_t[state_idx]) or np.isinf(a_t[state_idx]) or abs(a_t[state_idx]) > threshold:\n",
    "                                # Use a more conservative value but preserve some variability\n",
    "                                pattern_factor = 0.95 + 0.1 * (w / (rmw-1))\n",
    "                                a_t[state_idx] = np.sign(a_t[state_idx]) * min(threshold, abs(m_obs) * pattern_factor)\n",
    "                        \n",
    "                        # 5. Verify the constraint is reasonably enforced (for debugging)\n",
    "                        if self.temp_agg == 'mean':\n",
    "                            agg_value = np.mean([a_t[monthly_start + w*Nm + m] for w in range(rmw)])\n",
    "                        else:\n",
    "                            agg_value = np.sum([a_t[monthly_start + w*Nm + m] for w in range(rmw)])\n",
    "                        \n",
    "                        # Print verification for first few draws\n",
    "                        if j == 0 and t < 10:\n",
    "                            error = abs(agg_value - m_obs)\n",
    "                            print(f\"  Month {m_idx+1}, Var {m+1}: Target={m_obs:.8f}, Achieved={agg_value:.8f}, Error={error:.10f}\")\n",
    "                \n",
    "                # Quarter-end constraint enforcement using measurement equation - similar approach\n",
    "                if is_quarter_end and q_idx >= 0 and q_idx < YQ.shape[0]:\n",
    "                    for q in range(Nq):\n",
    "                        # Get observed quarterly value\n",
    "                        q_obs = YQ[q_idx, q]\n",
    "                        var_block_idx = Nw + Nm + q\n",
    "                        \n",
    "                        # 1. Set VAR block variable with high precision\n",
    "                        H_phantom = np.zeros((1, nstate))\n",
    "                        H_phantom[0, var_block_idx] = 1.0\n",
    "                        y_phantom = np.array([q_obs])\n",
    "                        R_phantom = np.array([[1e-12]])\n",
    "                        \n",
    "                        # Kalman gain for phantom observation\n",
    "                        S_phantom = H_phantom @ P_t @ H_phantom.T + R_phantom\n",
    "                        K_phantom = P_t @ H_phantom.T @ np.linalg.inv(S_phantom)\n",
    "                        \n",
    "                        # Apply update\n",
    "                        a_t = a_t + K_phantom @ (y_phantom - H_phantom @ a_t)\n",
    "                        P_t = P_t - K_phantom @ H_phantom @ P_t\n",
    "                        \n",
    "                        # 2. Enforce temporal aggregation constraint\n",
    "                        H_agg = np.zeros((1, nstate))\n",
    "                        for w in range(rqw):\n",
    "                            state_idx = quarterly_start + w*Nq + q\n",
    "                            if self.temp_agg == 'mean':\n",
    "                                H_agg[0, state_idx] = 1.0/rqw\n",
    "                            else:  # 'sum'\n",
    "                                H_agg[0, state_idx] = 1.0\n",
    "                        \n",
    "                        # Use phantom observation\n",
    "                        y_agg = np.array([q_obs])\n",
    "                        R_agg = np.array([[1e-12]])\n",
    "                        \n",
    "                        # Kalman gain for aggregation\n",
    "                        S_agg = H_agg @ P_t @ H_agg.T + R_agg\n",
    "                        K_agg = P_t @ H_agg.T @ np.linalg.inv(S_agg)\n",
    "                        \n",
    "                        # Apply update\n",
    "                        a_t = a_t + K_agg @ (y_agg - H_agg @ a_t)\n",
    "                        P_t = P_t - K_agg @ H_agg @ P_t\n",
    "                        \n",
    "                        # 3. Enforce first-week alignment with VAR block\n",
    "                        H_align = np.zeros((1, nstate))\n",
    "                        H_align[0, var_block_idx] = 1.0  # VAR block\n",
    "                        H_align[0, quarterly_start + q] = -1.0  # First week\n",
    "                        \n",
    "                        y_align = np.array([0.0])  # Zero difference\n",
    "                        R_align = np.array([[1e-12]])\n",
    "                        \n",
    "                        # Kalman gain for alignment\n",
    "                        S_align = H_align @ P_t @ H_align.T + R_align\n",
    "                        K_align = P_t @ H_align.T @ np.linalg.inv(S_align)\n",
    "                        \n",
    "                        # Apply update\n",
    "                        a_t = a_t + K_align @ (y_align - H_align @ a_t)\n",
    "                        P_t = P_t - K_align @ H_align @ P_t\n",
    "                        \n",
    "                        # 4. Apply value clipping to prevent extremes\n",
    "                        threshold = 3.0\n",
    "                        for w in range(rqw):\n",
    "                            state_idx = quarterly_start + w*Nq + q\n",
    "                            if np.isnan(a_t[state_idx]) or np.isinf(a_t[state_idx]) or abs(a_t[state_idx]) > threshold:\n",
    "                                # Use conservative value but preserve some variability\n",
    "                                pattern_factor = 0.95 + 0.1 * np.sin(np.pi * w / rqw)\n",
    "                                a_t[state_idx] = np.sign(a_t[state_idx]) * min(threshold, abs(q_obs) * pattern_factor)\n",
    "                        \n",
    "                        # 5. Verify constraint (for debugging)\n",
    "                        if self.temp_agg == 'mean':\n",
    "                            agg_value = np.mean([a_t[quarterly_start + w*Nq + q] for w in range(rqw)])\n",
    "                        else:\n",
    "                            agg_value = np.sum([a_t[quarterly_start + w*Nq + q] for w in range(rqw)])\n",
    "                        \n",
    "                        # Print verification for first few draws\n",
    "                        if j == 0 and t < 10:\n",
    "                            error = abs(agg_value - q_obs)\n",
    "                            print(f\"  Quarter {q_idx+1}, Var {q+1}: Target={q_obs:.8f}, Achieved={agg_value:.8f}, Error={error:.10f}\")\n",
    "                \n",
    "                # ENHANCED VALUE CLAMPING\n",
    "                # Apply global state value clipping\n",
    "                for i in range(nstate):\n",
    "                    # More aggressive clipping for latent states\n",
    "                    if i >= monthly_start:\n",
    "                        if np.isnan(a_t[i]) or np.isinf(a_t[i]):\n",
    "                            a_t[i] = 0.0  # Reset to zero if NaN or Inf\n",
    "                        elif abs(a_t[i]) > 3.0:  # Stricter threshold\n",
    "                            a_t[i] = np.sign(a_t[i]) * 3.0  # Clip to ±3.0\n",
    "                            \n",
    "                    # Standard clipping for VAR block\n",
    "                    else:\n",
    "                        if np.isnan(a_t[i]) or np.isinf(a_t[i]):\n",
    "                            a_t[i] = 0.0\n",
    "                        elif abs(a_t[i]) > 5.0:\n",
    "                            a_t[i] = np.sign(a_t[i]) * 5.0\n",
    "                \n",
    "                # ADDITIONAL GLOBAL STATE MONITORING\n",
    "                # Periodically scan and reset problematic states\n",
    "                if t % 10 == 0:\n",
    "                    # Check for any remaining extreme values or instabilities\n",
    "                    for i in range(nstate):\n",
    "                        if abs(a_t[i]) > 2.0 and i >= monthly_start:\n",
    "                            # For latent states, set to conservative default if still extreme\n",
    "                            if i < quarterly_start:  # Monthly latent\n",
    "                                m = (i - monthly_start) % Nm\n",
    "                                w = (i - monthly_start) // Nm\n",
    "                                if m_idx >= 0 and m_idx < YM.shape[0]:\n",
    "                                    # Set to monthly value with small deviation\n",
    "                                    m_val = YM[m_idx, m]\n",
    "                                    a_t[i] = m_val * (0.95 + 0.1 * w / rmw)\n",
    "                                else:\n",
    "                                    a_t[i] = 0.5  # Conservative default\n",
    "                            else:  # Quarterly latent\n",
    "                                q = (i - quarterly_start) % Nq\n",
    "                                w = (i - quarterly_start) // Nq\n",
    "                                if q_idx >= 0 and q_idx < YQ.shape[0]:\n",
    "                                    # Set to quarterly value with small deviation\n",
    "                                    q_val = YQ[q_idx, q]\n",
    "                                    a_t[i] = q_val * (0.95 + 0.1 * w / rqw)\n",
    "                                else:\n",
    "                                    a_t[i] = 0.5\n",
    "                                \n",
    "                            # Reduce uncertainty for reset states\n",
    "                            P_t[i, i] = 1e-6\n",
    "                \n",
    "            except np.linalg.LinAlgError as e:\n",
    "                if j == 0:\n",
    "                    print(f\"Warning: Matrix inversion failed at t={t}. Using prediction only. Error: {str(e)}\")\n",
    "                a_t = a_pred\n",
    "                P_t = P_pred\n",
    "                \n",
    "                # Apply value clamping even when falling back to prediction\n",
    "                threshold = 5.0\n",
    "                for i in range(len(a_t)):\n",
    "                    if np.isnan(a_t[i]) or np.isinf(a_t[i]) or abs(a_t[i]) > threshold:\n",
    "                        a_t[i] = threshold * np.sign(a_t[i]) if a_t[i] != 0 else 0.001\n",
    "            \n",
    "            # Store filtered state and covariance\n",
    "            a_filtered[t] = a_t\n",
    "            P_filtered[t] = P_t\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Period 1: week_idx=12, quarter_end=False, month_end=False\n",
      "Period 2: week_idx=13, quarter_end=False, month_end=False\n",
      "Period 3: week_idx=14, quarter_end=False, month_end=False\n",
      "Period 4: week_idx=15, quarter_end=False, month_end=True\n",
      "  Monthly observation: [ 0.00543815  0.00273287 -0.00063385]\n",
      "  Month 4, Var 1: Target=0.00543815, Achieved=0.00543815, Error=0.0000000003\n",
      "  Month 4, Var 2: Target=0.00273287, Achieved=0.00273287, Error=0.0000000002\n",
      "  Month 4, Var 3: Target=-0.00063385, Achieved=-0.00063385, Error=0.0000000001\n",
      "Period 5: week_idx=16, quarter_end=False, month_end=False\n",
      "  Month 5, Var 1: Target=-0.00016291, Achieved=-0.00016291, Error=0.0000000001\n",
      "  Month 5, Var 2: Target=-0.00238576, Achieved=-0.00238576, Error=0.0000000001\n",
      "  Month 5, Var 3: Target=-0.00158969, Achieved=-0.00158969, Error=0.0000000001\n"
     ]
    }
   ],
   "source": [
    "        if j > 0:\n",
    "            a_t = a_draws[j-1, -1]\n",
    "            P_t = P_filtered[-1]\n",
    "        \n",
    "        # Kalman filter loop through all periods\n",
    "        for t in range(nobs):\n",
    "            # Current week index\n",
    "            w_idx = T0 + t\n",
    "            \n",
    "            # PREDICTION STEP\n",
    "            # --------------\n",
    "            a_pred = F @ a_t + c.flatten()\n",
    "            P_pred = F @ P_t @ F.T + Q\n",
    "            P_pred = 0.5 * (P_pred + P_pred.T)  # Ensure perfect symmetry\n",
    "            \n",
    "            # DETERMINE AVAILABLE OBSERVATIONS\n",
    "            # -----------------------------\n",
    "            \n",
    "            # Check which observations are available at this period\n",
    "            is_quarter_end = q_obs_periods[w_idx] if w_idx < len(q_obs_periods) else False\n",
    "            is_month_end = m_obs_periods[w_idx] if w_idx < len(m_obs_periods) else False\n",
    "            \n",
    "            # Get indices for the observation vectors\n",
    "            q_idx = w_idx // rqw if is_quarter_end else -1\n",
    "            m_idx = w_idx // rmw if is_month_end else -1\n",
    "            \n",
    "            # Debug output for first few periods\n",
    "            if j == 0 and t < 5:\n",
    "                print(f\"Period {t+1}: week_idx={w_idx}, quarter_end={is_quarter_end}, month_end={is_month_end}\")\n",
    "                if is_quarter_end:\n",
    "                    print(f\"  Quarterly observation: {YQ[q_idx]}\")\n",
    "                if is_month_end:\n",
    "                    print(f\"  Monthly observation: {YM[m_idx]}\")\n",
    "            \n",
    "            # BUILD ENHANCED MEASUREMENT MATRICES AND OBSERVATION VECTOR\n",
    "            # -----------------------------------------------------\n",
    "            \n",
    "            # Start with weekly observations (always available)\n",
    "            H_matrices = [H_w]\n",
    "            y_obs = [YW[w_idx]]\n",
    "            \n",
    "            # Add monthly observations if available\n",
    "            monthly_constraints_added = False\n",
    "            if is_month_end and m_idx >= 0 and m_idx < YM.shape[0]:\n",
    "                H_matrices.append(H_m)\n",
    "                y_obs.append(YM[m_idx])\n",
    "                \n",
    "                # Always add the constraint that links VAR block to latent states\n",
    "                H_matrices.append(H_m_constraint)\n",
    "                y_obs.append(np.zeros(Nm))  # Zero difference means equality constraint\n",
    "                monthly_constraints_added = True\n",
    "            \n",
    "            # Add quarterly observations if available\n",
    "            quarterly_constraints_added = False\n",
    "            if is_quarter_end and q_idx >= 0 and q_idx < YQ.shape[0]:\n",
    "                H_matrices.append(H_q)\n",
    "                y_obs.append(YQ[q_idx])\n",
    "                \n",
    "                # Always add the constraint that links VAR block to latent states\n",
    "                H_matrices.append(H_q_constraint)\n",
    "                y_obs.append(np.zeros(Nq))  # Zero difference means equality constraint\n",
    "                quarterly_constraints_added = True\n",
    "            \n",
    "            # Also enforce VAR-latent alignment constraints at every period\n",
    "            # (not just at month/quarter end)\n",
    "            if not monthly_constraints_added and t % 5 == 0:  # Every 5 periods to avoid too much constraint\n",
    "                H_matrices.append(H_m_constraint)\n",
    "                y_obs.append(np.zeros(Nm))\n",
    "            \n",
    "            if not quarterly_constraints_added and t % 10 == 0:  # Less frequent for quarterly\n",
    "                H_matrices.append(H_q_constraint)\n",
    "                y_obs.append(np.zeros(Nq))\n",
    "            \n",
    "            # Combined measurement matrix and observation vector\n",
    "            H = np.vstack(H_matrices)\n",
    "            y = np.concatenate(y_obs)\n",
    "            \n",
    "            # DIFFERENT MEASUREMENT NOISE BY FREQUENCY - EXTREMELY PRECISE FOR CONSTRAINTS\n",
    "            # ---------------------------------------------------------------------\n",
    "            \n",
    "            # Create measurement noise matrix with precision scaled by frequency\n",
    "            R = np.zeros((len(y), len(y)))\n",
    "            \n",
    "            # Current position in the observation vector\n",
    "            obs_pos = 0\n",
    "            \n",
    "            # Weekly measurement noise (standard precision)\n",
    "            R[obs_pos:obs_pos+Nw, obs_pos:obs_pos+Nw] = np.eye(Nw) * 1e-3\n",
    "            obs_pos += Nw\n",
    "            \n",
    "            # Monthly measurement noise (extreme precision to enforce constraint)\n",
    "            if is_month_end and m_idx >= 0 and m_idx < YM.shape[0]:\n",
    "                R[obs_pos:obs_pos+Nm, obs_pos:obs_pos+Nm] = np.eye(Nm) * 1e-12\n",
    "                obs_pos += Nm\n",
    "                \n",
    "                # VAR-to-latent constraint noise (extremely low)\n",
    "                R[obs_pos:obs_pos+Nm, obs_pos:obs_pos+Nm] = np.eye(Nm) * 1e-14\n",
    "                obs_pos += Nm\n",
    "            \n",
    "            # Quarterly measurement noise (even more extreme precision)\n",
    "            if is_quarter_end and q_idx >= 0 and q_idx < YQ.shape[0]:\n",
    "                R[obs_pos:obs_pos+Nq, obs_pos:obs_pos+Nq] = np.eye(Nq) * 1e-12\n",
    "                obs_pos += Nq\n",
    "                \n",
    "                # VAR-to-latent constraint noise (extremely low)\n",
    "                R[obs_pos:obs_pos+Nq, obs_pos:obs_pos+Nq] = np.eye(Nq) * 1e-14\n",
    "                obs_pos += Nq\n",
    "            \n",
    "            # Add VAR-latent alignment constraints outside month/quarter end if included\n",
    "            if not monthly_constraints_added and t % 5 == 0:\n",
    "                R[obs_pos:obs_pos+Nm, obs_pos:obs_pos+Nm] = np.eye(Nm) * 1e-12\n",
    "                obs_pos += Nm\n",
    "                \n",
    "            if not quarterly_constraints_added and t % 10 == 0:\n",
    "                R[obs_pos:obs_pos+Nq, obs_pos:obs_pos+Nq] = np.eye(Nq) * 1e-12\n",
    "                obs_pos += Nq\n",
    "            \n",
    "            # UPDATE STEP WITH NUMERICAL STABILITY\n",
    "            # ------------------------------\n",
    "            y_hat = H @ a_pred\n",
    "            nu = y - y_hat  # Innovation\n",
    "            \n",
    "            # Innovation covariance - with careful regularization\n",
    "            S = H @ P_pred @ H.T + R\n",
    "            S = 0.5 * (S + S.T)  # Ensure perfect symmetry\n",
    "            \n",
    "            # Add regularization more safely\n",
    "            S_reg = S.copy()\n",
    "            try:\n",
    "                # Use eigvalsh for symmetric matrices which returns real eigenvalues\n",
    "                eig_vals = np.linalg.eigvalsh(S)\n",
    "                min_eig = np.min(eig_vals)\n",
    "                if min_eig < 1e-10:\n",
    "                    S_reg += np.eye(S.shape[0]) * (1e-10 - min_eig)\n",
    "            except:\n",
    "                # Fallback to simple regularization if eigvalsh fails\n",
    "                S_reg += np.eye(S.shape[0]) * 1e-8\n",
    "                if j == 0 and t < 10:\n",
    "                    print(f\"Warning: Using diagonal regularization for S at t={t}\")\n",
    "            \n",
    "            try:\n",
    "                # Kalman gain\n",
    "                K = P_pred @ H.T @ invert_matrix(S_reg)\n",
    "                \n",
    "                # Update state and covariance\n",
    "                a_t = a_pred + K @ nu\n",
    "                P_t = P_pred - K @ H @ P_pred\n",
    "                \n",
    "                # Force symmetry more carefully\n",
    "                P_t = 0.5 * (P_t + P_t.T)  # Ensure perfect symmetry\n",
    "                \n",
    "                # Force positive definiteness more robustly\n",
    "                try:\n",
    "                    # Use eigvalsh for symmetric matrices\n",
    "                    eig_vals = np.linalg.eigvalsh(P_t)\n",
    "                    min_eig = np.min(eig_vals)\n",
    "                    if min_eig < 1e-8:\n",
    "                        P_t += np.eye(P_t.shape[0]) * (1e-8 - min_eig)\n",
    "                except:\n",
    "                    # If eigvalsh fails, use a more brute-force approach\n",
    "                    P_t += np.eye(P_t.shape[0]) * 1e-6\n",
    "                    if j == 0 and t < 10:\n",
    "                        print(f\"Warning: Using diagonal regularization for P_t at t={t}\")\n",
    "                \n",
    "                # ENHANCED MEASUREMENT EQUATION ENFORCEMENT\n",
    "                # ------------------------------------------------\n",
    "                \n",
    "                # Month-end constraint enforcement using the measurement equation\n",
    "                if is_month_end and m_idx >= 0 and m_idx < YM.shape[0]:\n",
    "                    for m in range(Nm):\n",
    "                        # Get observed monthly value\n",
    "                        m_obs = YM[m_idx, m]\n",
    "                        var_block_idx = Nw + m\n",
    "                        \n",
    "                        # 1. First let's set the VAR block variable to match observation with high precision\n",
    "                        # This is done through a \"phantom\" observation using the Kalman update\n",
    "                        H_phantom = np.zeros((1, nstate))\n",
    "                        H_phantom[0, var_block_idx] = 1.0\n",
    "                        y_phantom = np.array([m_obs])\n",
    "                        R_phantom = np.array([[1e-12]])  # Very low measurement noise\n",
    "                        \n",
    "                        # Kalman gain for this phantom observation\n",
    "                        S_phantom = H_phantom @ P_t @ H_phantom.T + R_phantom\n",
    "                        K_phantom = P_t @ H_phantom.T @ np.linalg.inv(S_phantom)\n",
    "                        \n",
    "                        # Apply update\n",
    "                        a_t = a_t + K_phantom @ (y_phantom - H_phantom @ a_t)\n",
    "                        P_t = P_t - K_phantom @ H_phantom @ P_t\n",
    "                        \n",
    "                        # 2. Now enforce the temporal aggregation constraint with high precision\n",
    "                        # Build measurement matrix for aggregation\n",
    "                        H_agg = np.zeros((1, nstate))\n",
    "                        for w in range(rmw):\n",
    "                            state_idx = monthly_start + w*Nm + m\n",
    "                            if self.temp_agg == 'mean':\n",
    "                                H_agg[0, state_idx] = 1.0/rmw\n",
    "                            else:  # 'sum'\n",
    "                                H_agg[0, state_idx] = 1.0\n",
    "                        \n",
    "                        # Use phantom observation for aggregation\n",
    "                        y_agg = np.array([m_obs])\n",
    "                        R_agg = np.array([[1e-12]])  # Very low measurement noise\n",
    "                        \n",
    "                        # Kalman gain for aggregation\n",
    "                        S_agg = H_agg @ P_t @ H_agg.T + R_agg\n",
    "                        K_agg = P_t @ H_agg.T @ np.linalg.inv(S_agg)\n",
    "                        \n",
    "                        # Apply update\n",
    "                        a_t = a_t + K_agg @ (y_agg - H_agg @ a_t)\n",
    "                        P_t = P_t - K_agg @ H_agg @ P_t\n",
    "                        \n",
    "                        # 3. Enforce first-week alignment with VAR block\n",
    "                        H_align = np.zeros((1, nstate))\n",
    "                        H_align[0, var_block_idx] = 1.0  # VAR block\n",
    "                        H_align[0, monthly_start + m] = -1.0  # First week\n",
    "                        \n",
    "                        y_align = np.array([0.0])  # Zero difference\n",
    "                        R_align = np.array([[1e-12]])\n",
    "                        \n",
    "                        # Kalman gain for alignment\n",
    "                        S_align = H_align @ P_t @ H_align.T + R_align\n",
    "                        K_align = P_t @ H_align.T @ np.linalg.inv(S_align)\n",
    "                        \n",
    "                        # Apply update\n",
    "                        a_t = a_t + K_align @ (y_align - H_align @ a_t)\n",
    "                        P_t = P_t - K_align @ H_align @ P_t\n",
    "                        \n",
    "                        # 4. Apply value clipping afterward to prevent extreme values\n",
    "                        threshold = 3.0\n",
    "                        for w in range(rmw):\n",
    "                            state_idx = monthly_start + w*Nm + m\n",
    "                            if np.isnan(a_t[state_idx]) or np.isinf(a_t[state_idx]) or abs(a_t[state_idx]) > threshold:\n",
    "                                # Use a more conservative value but preserve some variability\n",
    "                                pattern_factor = 0.95 + 0.1 * (w / (rmw-1))\n",
    "                                a_t[state_idx] = np.sign(a_t[state_idx]) * min(threshold, abs(m_obs) * pattern_factor)\n",
    "                        \n",
    "                        # 5. Verify the constraint is reasonably enforced (for debugging)\n",
    "                        if self.temp_agg == 'mean':\n",
    "                            agg_value = np.mean([a_t[monthly_start + w*Nm + m] for w in range(rmw)])\n",
    "                        else:\n",
    "                            agg_value = np.sum([a_t[monthly_start + w*Nm + m] for w in range(rmw)])\n",
    "                        \n",
    "                        # Print verification for first few draws\n",
    "                        if j == 0 and t < 10:\n",
    "                            error = abs(agg_value - m_obs)\n",
    "                            print(f\"  Month {m_idx+1}, Var {m+1}: Target={m_obs:.8f}, Achieved={agg_value:.8f}, Error={error:.10f}\")\n",
    "                \n",
    "                # Quarter-end constraint enforcement using measurement equation - similar approach\n",
    "                if is_quarter_end and q_idx >= 0 and q_idx < YQ.shape[0]:\n",
    "                    for q in range(Nq):\n",
    "                        # Get observed quarterly value\n",
    "                        q_obs = YQ[q_idx, q]\n",
    "                        var_block_idx = Nw + Nm + q\n",
    "                        \n",
    "                        # 1. Set VAR block variable with high precision\n",
    "                        H_phantom = np.zeros((1, nstate))\n",
    "                        H_phantom[0, var_block_idx] = 1.0\n",
    "                        y_phantom = np.array([q_obs])\n",
    "                        R_phantom = np.array([[1e-12]])\n",
    "                        \n",
    "                        # Kalman gain for phantom observation\n",
    "                        S_phantom = H_phantom @ P_t @ H_phantom.T + R_phantom\n",
    "                        K_phantom = P_t @ H_phantom.T @ np.linalg.inv(S_phantom)\n",
    "                        \n",
    "                        # Apply update\n",
    "                        a_t = a_t + K_phantom @ (y_phantom - H_phantom @ a_t)\n",
    "                        P_t = P_t - K_phantom @ H_phantom @ P_t\n",
    "                        \n",
    "                        # 2. Enforce temporal aggregation constraint\n",
    "                        H_agg = np.zeros((1, nstate))\n",
    "                        for w in range(rqw):\n",
    "                            state_idx = quarterly_start + w*Nq + q\n",
    "                            if self.temp_agg == 'mean':\n",
    "                                H_agg[0, state_idx] = 1.0/rqw\n",
    "                            else:  # 'sum'\n",
    "                                H_agg[0, state_idx] = 1.0\n",
    "                        \n",
    "                        # Use phantom observation\n",
    "                        y_agg = np.array([q_obs])\n",
    "                        R_agg = np.array([[1e-12]])\n",
    "                        \n",
    "                        # Kalman gain for aggregation\n",
    "                        S_agg = H_agg @ P_t @ H_agg.T + R_agg\n",
    "                        K_agg = P_t @ H_agg.T @ np.linalg.inv(S_agg)\n",
    "                        \n",
    "                        # Apply update\n",
    "                        a_t = a_t + K_agg @ (y_agg - H_agg @ a_t)\n",
    "                        P_t = P_t - K_agg @ H_agg @ P_t\n",
    "                        \n",
    "                        # 3. Enforce first-week alignment with VAR block\n",
    "                        H_align = np.zeros((1, nstate))\n",
    "                        H_align[0, var_block_idx] = 1.0  # VAR block\n",
    "                        H_align[0, quarterly_start + q] = -1.0  # First week\n",
    "                        \n",
    "                        y_align = np.array([0.0])  # Zero difference\n",
    "                        R_align = np.array([[1e-12]])\n",
    "                        \n",
    "                        # Kalman gain for alignment\n",
    "                        S_align = H_align @ P_t @ H_align.T + R_align\n",
    "                        K_align = P_t @ H_align.T @ np.linalg.inv(S_align)\n",
    "                        \n",
    "                        # Apply update\n",
    "                        a_t = a_t + K_align @ (y_align - H_align @ a_t)\n",
    "                        P_t = P_t - K_align @ H_align @ P_t\n",
    "                        \n",
    "                        # 4. Apply value clipping to prevent extremes\n",
    "                        threshold = 3.0\n",
    "                        for w in range(rqw):\n",
    "                            state_idx = quarterly_start + w*Nq + q\n",
    "                            if np.isnan(a_t[state_idx]) or np.isinf(a_t[state_idx]) or abs(a_t[state_idx]) > threshold:\n",
    "                                # Use conservative value but preserve some variability\n",
    "                                pattern_factor = 0.95 + 0.1 * np.sin(np.pi * w / rqw)\n",
    "                                a_t[state_idx] = np.sign(a_t[state_idx]) * min(threshold, abs(q_obs) * pattern_factor)\n",
    "                        \n",
    "                        # 5. Verify constraint (for debugging)\n",
    "                        if self.temp_agg == 'mean':\n",
    "                            agg_value = np.mean([a_t[quarterly_start + w*Nq + q] for w in range(rqw)])\n",
    "                        else:\n",
    "                            agg_value = np.sum([a_t[quarterly_start + w*Nq + q] for w in range(rqw)])\n",
    "                        \n",
    "                        # Print verification for first few draws\n",
    "                        if j == 0 and t < 10:\n",
    "                            error = abs(agg_value - q_obs)\n",
    "                            print(f\"  Quarter {q_idx+1}, Var {q+1}: Target={q_obs:.8f}, Achieved={agg_value:.8f}, Error={error:.10f}\")\n",
    "                \n",
    "                # ENHANCED VALUE CLAMPING\n",
    "                # Apply global state value clipping\n",
    "                for i in range(nstate):\n",
    "                    # More aggressive clipping for latent states\n",
    "                    if i >= monthly_start:\n",
    "                        if np.isnan(a_t[i]) or np.isinf(a_t[i]):\n",
    "                            a_t[i] = 0.0  # Reset to zero if NaN or Inf\n",
    "                        elif abs(a_t[i]) > 3.0:  # Stricter threshold\n",
    "                            a_t[i] = np.sign(a_t[i]) * 3.0  # Clip to ±3.0\n",
    "                            \n",
    "                    # Standard clipping for VAR block\n",
    "                    else:\n",
    "                        if np.isnan(a_t[i]) or np.isinf(a_t[i]):\n",
    "                            a_t[i] = 0.0\n",
    "                        elif abs(a_t[i]) > 5.0:\n",
    "                            a_t[i] = np.sign(a_t[i]) * 5.0\n",
    "                \n",
    "                # ADDITIONAL GLOBAL STATE MONITORING\n",
    "                # Periodically scan and reset problematic states\n",
    "                if t % 10 == 0:\n",
    "                    # Check for any remaining extreme values or instabilities\n",
    "                    for i in range(nstate):\n",
    "                        if abs(a_t[i]) > 2.0 and i >= monthly_start:\n",
    "                            # For latent states, set to conservative default if still extreme\n",
    "                            if i < quarterly_start:  # Monthly latent\n",
    "                                m = (i - monthly_start) % Nm\n",
    "                                w = (i - monthly_start) // Nm\n",
    "                                if m_idx >= 0 and m_idx < YM.shape[0]:\n",
    "                                    # Set to monthly value with small deviation\n",
    "                                    m_val = YM[m_idx, m]\n",
    "                                    a_t[i] = m_val * (0.95 + 0.1 * w / rmw)\n",
    "                                else:\n",
    "                                    a_t[i] = 0.5  # Conservative default\n",
    "                            else:  # Quarterly latent\n",
    "                                q = (i - quarterly_start) % Nq\n",
    "                                w = (i - quarterly_start) // Nq\n",
    "                                if q_idx >= 0 and q_idx < YQ.shape[0]:\n",
    "                                    # Set to quarterly value with small deviation\n",
    "                                    q_val = YQ[q_idx, q]\n",
    "                                    a_t[i] = q_val * (0.95 + 0.1 * w / rqw)\n",
    "                                else:\n",
    "                                    a_t[i] = 0.5\n",
    "                                \n",
    "                            # Reduce uncertainty for reset states\n",
    "                            P_t[i, i] = 1e-6\n",
    "                \n",
    "            except np.linalg.LinAlgError as e:\n",
    "                if j == 0:\n",
    "                    print(f\"Warning: Matrix inversion failed at t={t}. Using prediction only. Error: {str(e)}\")\n",
    "                a_t = a_pred\n",
    "                P_t = P_pred\n",
    "                \n",
    "                # Apply value clamping even when falling back to prediction\n",
    "                threshold = 5.0\n",
    "                for i in range(len(a_t)):\n",
    "                    if np.isnan(a_t[i]) or np.isinf(a_t[i]) or abs(a_t[i]) > threshold:\n",
    "                        a_t[i] = threshold * np.sign(a_t[i]) if a_t[i] != 0 else 0.001\n",
    "            \n",
    "            # Store filtered state and covariance\n",
    "            a_filtered[t] = a_t\n",
    "            P_filtered[t] = P_t\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rqw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08333333333333333"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.0/rqw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.25,\n",
       "        0.  , 0.  , 0.25, 0.  , 0.  , 0.25, 0.  , 0.  , 0.25, 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.24938498e-03,  7.04779213e-03,  1.10641382e-02, ...,\n",
       "        -5.76574804e-04, -1.87133356e-04, -3.47150157e-04],\n",
       "       [ 8.00787298e-03,  4.56441861e-03,  8.50702855e-03, ...,\n",
       "        -6.26571196e-04, -1.08108895e-04, -5.76617472e-04],\n",
       "       [ 5.80858959e-03,  3.53774370e-03,  6.15794667e-03, ...,\n",
       "        -5.19578395e-04,  2.88983520e-05, -6.26596601e-04],\n",
       "       ...,\n",
       "       [ 1.79240788e-02,  1.40871017e-02,  1.60752212e-02, ...,\n",
       "         6.08880454e-05, -4.51271924e-04,  4.50311306e-05],\n",
       "       [ 1.33104170e-02,  1.06256902e-02,  1.16744120e-02, ...,\n",
       "         6.80558416e-04, -5.75247756e-04,  6.08831725e-05],\n",
       "       [ 1.08875014e-02,  8.13670500e-03,  1.15817194e-02, ...,\n",
       "        -3.47144199e-04,  7.47242870e-04,  6.80558416e-04]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_filtered"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
